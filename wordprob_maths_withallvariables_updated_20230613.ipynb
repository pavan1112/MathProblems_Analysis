{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrn3Kw4UPb6A"
   },
   "source": [
    "**Math Word Problem Readability Score**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeulMH9iSLoZ"
   },
   "source": [
    "Experimented with all variables Raw attributes\n",
    " - (MathSymbolsPerSentence), (MathSymbolsPerSentence), etc...\n",
    "\n",
    "Raw attributes - GF*, FK*, SMOG*, ARI*, CL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5Hq37qAd11NU"
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxyMINAGqv_T"
   },
   "source": [
    "**IMPORT THE LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy as scp\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62pYi-RIq0KZ"
   },
   "source": [
    "**READ THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dt8i-oQSHD7L"
   },
   "outputs": [],
   "source": [
    "org_data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FngGh7cNq3pe"
   },
   "source": [
    "**CHECK THE FIRST FEW ROWS OF THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7dvvC30hHNq4",
    "outputId": "190e8e0c-719d-4525-b496-88411758ccba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>Type</th>\n",
       "      <th>Solution</th>\n",
       "      <th>Extracted words(List)</th>\n",
       "      <th>Extracted Num(List)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are constants    alpha  and    beta  suc...</td>\n",
       "      <td>Level 5</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>The numerator  x^2 - 80x + 1551  factors as  (...</td>\n",
       "      <td>['There', 'are', 'constants', 'alpha', 'and', ...</td>\n",
       "      <td>['2', '80', '1551', '2', '57', '2970']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The length of the segment between the points  ...</td>\n",
       "      <td>Level 5</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>By the distance formula, the distance from  (2...</td>\n",
       "      <td>['The', 'length', 'of', 'the', 'segment', 'bet...</td>\n",
       "      <td>['2', '4', '4', '1', '2', '10']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>Level 5</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>If Chewbacca loses one pack of cherry gum, the...</td>\n",
       "      <td>['Chewbacca', 'has', 'pieces', 'of', 'cherry',...</td>\n",
       "      <td>['20', '30', '5']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>Level 5</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>Setting  x = 3,  we get  f(3) = -1.  Since  -1...</td>\n",
       "      <td>['For', 'some', 'constants', 'a', 'and', 'b', ...</td>\n",
       "      <td>['2', '8', '3', '2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>Level 2</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>The arithmetic sequence 1, 3, 5,    dots , 17,...</td>\n",
       "      <td>['Calculate', 'the', 'sum', 'cdots']</td>\n",
       "      <td>['1', '3', '5', '15', '17']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem    Level      Type  \\\n",
       "0  There are constants    alpha  and    beta  suc...  Level 5  Algebra   \n",
       "1  The length of the segment between the points  ...  Level 5  Algebra   \n",
       "2  Chewbacca has 20 pieces of cherry gum and 30 p...  Level 5  Algebra   \n",
       "3  For some constants  a  and  b,  let   [f(x) = ...  Level 5  Algebra   \n",
       "4  Calculate the sum  1 + 3 + 5 +   cdots + 15 + ...  Level 2  Algebra   \n",
       "\n",
       "                                            Solution  \\\n",
       "0  The numerator  x^2 - 80x + 1551  factors as  (...   \n",
       "1  By the distance formula, the distance from  (2...   \n",
       "2  If Chewbacca loses one pack of cherry gum, the...   \n",
       "3  Setting  x = 3,  we get  f(3) = -1.  Since  -1...   \n",
       "4  The arithmetic sequence 1, 3, 5,    dots , 17,...   \n",
       "\n",
       "                               Extracted words(List)  \\\n",
       "0  ['There', 'are', 'constants', 'alpha', 'and', ...   \n",
       "1  ['The', 'length', 'of', 'the', 'segment', 'bet...   \n",
       "2  ['Chewbacca', 'has', 'pieces', 'of', 'cherry',...   \n",
       "3  ['For', 'some', 'constants', 'a', 'and', 'b', ...   \n",
       "4               ['Calculate', 'the', 'sum', 'cdots']   \n",
       "\n",
       "                      Extracted Num(List)  \n",
       "0  ['2', '80', '1551', '2', '57', '2970']  \n",
       "1         ['2', '4', '4', '1', '2', '10']  \n",
       "2                       ['20', '30', '5']  \n",
       "3                    ['2', '8', '3', '2']  \n",
       "4             ['1', '3', '5', '15', '17']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53bt_AW0q-q-"
   },
   "source": [
    "**EXTRACT TWO COLUMNS OF THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "gWkd8ej8HQg3",
    "outputId": "7a589d56-8f84-440c-cfe4-51b97f042e89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are constants    alpha  and    beta  suc...</td>\n",
       "      <td>Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The length of the segment between the points  ...</td>\n",
       "      <td>Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>Level 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>What is the slope of the line passing through ...</td>\n",
       "      <td>Level 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>Evaluate  i^{11} + i^{16} + i^{21} + i^{26} + ...</td>\n",
       "      <td>Level 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>If  a  is a constant such that  4x^2 - 12x + a...</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>Given  a   star b = a^2 + 2ab + b^2 , what is ...</td>\n",
       "      <td>Level 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>The graph of the function  f(x)  is shown belo...</td>\n",
       "      <td>Level 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Problem    Level \n",
       "0     There are constants    alpha  and    beta  suc...  Level 5\n",
       "1     The length of the segment between the points  ...  Level 5\n",
       "2     Chewbacca has 20 pieces of cherry gum and 30 p...  Level 5\n",
       "3     For some constants  a  and  b,  let   [f(x) = ...  Level 5\n",
       "4     Calculate the sum  1 + 3 + 5 +   cdots + 15 + ...  Level 2\n",
       "...                                                 ...      ...\n",
       "1739  What is the slope of the line passing through ...  Level 2\n",
       "1740  Evaluate  i^{11} + i^{16} + i^{21} + i^{26} + ...  Level 4\n",
       "1741  If  a  is a constant such that  4x^2 - 12x + a...  Level 3\n",
       "1742  Given  a   star b = a^2 + 2ab + b^2 , what is ...  Level 3\n",
       "1743  The graph of the function  f(x)  is shown belo...  Level 5\n",
       "\n",
       "[1744 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = org_data.iloc[:,0:2]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gjdru_ClQGeE"
   },
   "source": [
    "**CHECK FIRST FEW ROWS OF THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0Yrc6Gt3HS-8",
    "outputId": "378d8ba6-a453-4f42-fbee-96b7abed41f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are constants    alpha  and    beta  suc...</td>\n",
       "      <td>Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The length of the segment between the points  ...</td>\n",
       "      <td>Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>Level 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>Level 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem    Level \n",
       "0  There are constants    alpha  and    beta  suc...  Level 5\n",
       "1  The length of the segment between the points  ...  Level 5\n",
       "2  Chewbacca has 20 pieces of cherry gum and 30 p...  Level 5\n",
       "3  For some constants  a  and  b,  let   [f(x) = ...  Level 5\n",
       "4  Calculate the sum  1 + 3 + 5 +   cdots + 15 + ...  Level 2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Problem ']=df['Problem '].apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRfjvBsrQMq7"
   },
   "source": [
    "**CHECK FOR THE NUMBER OF UNIQUE CLASSES IN EACH COLUMN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jslgpLLHY2x",
    "outputId": "030876d5-6656-49e5-ee9c-d0660946f803"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Problem     1744\n",
       "Level          5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVLPM5osQWKU"
   },
   "source": [
    "**REMOVAL OF THE STRING PART (Level) FROM THE COLUMN \"Level\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uctEJtFQHao6"
   },
   "outputs": [],
   "source": [
    "df.iloc[:,1].replace(['Level 1', 'Level 2', 'Level 3', 'Level 4', 'Level 5'],\n",
    "                        [1, 2, 3, 4, 5], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZaEoYNKRMF-"
   },
   "source": [
    "**READ THE DATA OF MATH VOCAB**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tRpubCIZHrcB"
   },
   "outputs": [],
   "source": [
    "mathvocab = pd.read_csv(\"MathVocab.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-XMlMziOHwIr",
    "outputId": "9960042b-5174-4227-bfbc-cbe0afbd3171"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fractional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>solve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>equation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word\n",
       "0  fractional\n",
       "1     product\n",
       "2       solve\n",
       "3    equation\n",
       "4  expression"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathvocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNOCxWSQRdE_"
   },
   "source": [
    "**CREATED LIST OF ALL MATH VOCAB WORDS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7td9wiqWH2b_",
    "outputId": "00c73010-099f-42ac-b657-eda2522ccee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the list of a single column from the dataframe\n",
      " ['fractional', 'product', 'solve', 'equation', 'expression', 'rate', 'total', 'evaluate', 'compute', 'maximum', 'percent', 'arithmetic', 'sequence', 'integers', 'positive', 'distance', 'difference', 'how many', 'sum', 'square', 'cube', 'absolute value', 'cost', 'simplify', 'real number', 'what is the value', 'how much', 'operation', 'calculate', 'formula', 'positive integer', 'price', 'draw', 'length', 'subtract', 'lattice', 'largest', 'smallest', 'greatest number', 'equal', 'line', 'increase', 'multiple', 'average', 'number', 'divide', 'area', 'median', 'remainder', 'add', 'different', 'triange', 'equilateral', 'perimeter', 'size', 'angle', 'degree', 'measure', 'probability', 'segment', 'randomly chosen', 'prime number', 'random selection', 'randomly selected', 'digit', 'exact', 'paranethesis', 'obtuse', 'interior angle', 'ratio', 'range', 'multiply', 'function', 'domain', 'common fraction', 'hyperbola', 'graph', 'roots', 'even', 'odd', 'complex', 'plane', 'mid-point', 'conjugate', 'radicale', 'polynomial', 'interval', 'lowest', 'midpoint', 'consecutive', 'preceding', 'times', 'slope', 'endpoint', 'coordinate', 'proportional', 'reciprocal', 'numerator', 'denominator', 'set', 'inverse', 'simplest', 'intersection', 'point', 'intercept', 'cooefficient', 'ordered', 'inclusive', 'exclusive', 'vertices', 'altogether', 'together', 'decrease', 'successive', 'rectangle', 'diagonal', 'width', 'height', 'factor', 'circle', 'volume', 'cartesian', 'geometric', 'log', 'nearest', 'decimal', 'solution', 'amount', 'rationalize', 'more than', 'less than', 'more', 'less', 'count', 'find', 'binomial', 'common fractor', 'horizontal', 'vertical', 'polygon', 'greater than', 'divisor', 'parallelogram', 'complement', 'divisible', 'equally likely', 'reduce', 'distinct', 'adjacent', 'perpendicular', 'remove', 'randomly', 'older', 'newer', 'mean', 'whole number', 'at least', 'atmost', 'distribution', 'supplementary', 'symbols', 'exceed', 'ellipse', 'asymptote', 'sign', 'parabola', 'union', 'quotient', 'tangent', 'harmonic', 'oblique', 'symmetric', 'axis', 'variable', 'quadratic', 'improper fraction', 'proper fraction', 'straight line', 'discriminant', 'nonzero', 'diagram', 'progression', 'diameter', 'center', 'discount', 'infinite', 'undefined', 'radius', 'pi', 'parallel ', 'quarter', 'chord', 'circumference', 'combine', 'empirical', 'estimate', 'exponent', 'exponential', 'frequency', 'magnitude', 'matrix', 'opposite', 'ray', 'recursive', 'remaining', 'rhombus', 'rotation', 'similarity', 'statistics', 'transformation', 'trapezoid', 'trigonometry', 'vector', 'varies', 'sqrt', 'eliminate', 'constants', 'frac', 'find', 'express', 'exp'] \n",
      " <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "lst = mathvocab['Word'].tolist()\n",
    "\n",
    "print(\"the list of a single column from the dataframe\\n\",\n",
    "        lst,\n",
    "        \"\\n\",\n",
    "        type(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[i.lower() for i in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemm=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraction',\n",
       " 'product',\n",
       " 'solv',\n",
       " 'equat',\n",
       " 'express',\n",
       " 'rate',\n",
       " 'total',\n",
       " 'evalu',\n",
       " 'comput',\n",
       " 'maximum',\n",
       " 'percent',\n",
       " 'arithmet',\n",
       " 'sequenc',\n",
       " 'integ',\n",
       " 'posit',\n",
       " 'distanc',\n",
       " 'differ',\n",
       " 'how mani',\n",
       " 'sum',\n",
       " 'squar',\n",
       " 'cube',\n",
       " 'absolute valu',\n",
       " 'cost',\n",
       " 'simplifi',\n",
       " 'real numb',\n",
       " 'what is the valu',\n",
       " 'how much',\n",
       " 'oper',\n",
       " 'calcul',\n",
       " 'formula',\n",
       " 'positive integ',\n",
       " 'price',\n",
       " 'draw',\n",
       " 'length',\n",
       " 'subtract',\n",
       " 'lattic',\n",
       " 'largest',\n",
       " 'smallest',\n",
       " 'greatest numb',\n",
       " 'equal',\n",
       " 'line',\n",
       " 'increas',\n",
       " 'multipl',\n",
       " 'averag',\n",
       " 'number',\n",
       " 'divid',\n",
       " 'area',\n",
       " 'median',\n",
       " 'remaind',\n",
       " 'add',\n",
       " 'differ',\n",
       " 'triang',\n",
       " 'equilater',\n",
       " 'perimet',\n",
       " 'size',\n",
       " 'angl',\n",
       " 'degre',\n",
       " 'measur',\n",
       " 'probabl',\n",
       " 'segment',\n",
       " 'randomly chosen',\n",
       " 'prime numb',\n",
       " 'random select',\n",
       " 'randomly select',\n",
       " 'digit',\n",
       " 'exact',\n",
       " 'paranethesi',\n",
       " 'obtus',\n",
       " 'interior angl',\n",
       " 'ratio',\n",
       " 'rang',\n",
       " 'multipli',\n",
       " 'function',\n",
       " 'domain',\n",
       " 'common fract',\n",
       " 'hyperbola',\n",
       " 'graph',\n",
       " 'root',\n",
       " 'even',\n",
       " 'odd',\n",
       " 'complex',\n",
       " 'plane',\n",
       " 'mid-point',\n",
       " 'conjug',\n",
       " 'radical',\n",
       " 'polynomi',\n",
       " 'interv',\n",
       " 'lowest',\n",
       " 'midpoint',\n",
       " 'consecut',\n",
       " 'preced',\n",
       " 'time',\n",
       " 'slope',\n",
       " 'endpoint',\n",
       " 'coordin',\n",
       " 'proport',\n",
       " 'reciproc',\n",
       " 'numer',\n",
       " 'denomin',\n",
       " 'set',\n",
       " 'invers',\n",
       " 'simplest',\n",
       " 'intersect',\n",
       " 'point',\n",
       " 'intercept',\n",
       " 'cooeffici',\n",
       " 'order',\n",
       " 'inclus',\n",
       " 'exclus',\n",
       " 'vertic',\n",
       " 'altogeth',\n",
       " 'togeth',\n",
       " 'decreas',\n",
       " 'success',\n",
       " 'rectangl',\n",
       " 'diagon',\n",
       " 'width',\n",
       " 'height',\n",
       " 'factor',\n",
       " 'circl',\n",
       " 'volum',\n",
       " 'cartesian',\n",
       " 'geometr',\n",
       " 'log',\n",
       " 'nearest',\n",
       " 'decim',\n",
       " 'solut',\n",
       " 'amount',\n",
       " 'ration',\n",
       " 'more than',\n",
       " 'less than',\n",
       " 'more',\n",
       " 'less',\n",
       " 'count',\n",
       " 'find',\n",
       " 'binomi',\n",
       " 'common fractor',\n",
       " 'horizont',\n",
       " 'vertic',\n",
       " 'polygon',\n",
       " 'greater than',\n",
       " 'divisor',\n",
       " 'parallelogram',\n",
       " 'complement',\n",
       " 'divis',\n",
       " 'equally lik',\n",
       " 'reduc',\n",
       " 'distinct',\n",
       " 'adjac',\n",
       " 'perpendicular',\n",
       " 'remov',\n",
       " 'randomli',\n",
       " 'older',\n",
       " 'newer',\n",
       " 'mean',\n",
       " 'whole numb',\n",
       " 'at least',\n",
       " 'atmost',\n",
       " 'distribut',\n",
       " 'supplementari',\n",
       " 'symbol',\n",
       " 'exceed',\n",
       " 'ellips',\n",
       " 'asymptot',\n",
       " 'sign',\n",
       " 'parabola',\n",
       " 'union',\n",
       " 'quotient',\n",
       " 'tangent',\n",
       " 'harmon',\n",
       " 'obliqu',\n",
       " 'symmetr',\n",
       " 'axi',\n",
       " 'variabl',\n",
       " 'quadrat',\n",
       " 'improper fract',\n",
       " 'proper fract',\n",
       " 'straight lin',\n",
       " 'discrimin',\n",
       " 'nonzero',\n",
       " 'diagram',\n",
       " 'progress',\n",
       " 'diamet',\n",
       " 'center',\n",
       " 'discount',\n",
       " 'infinit',\n",
       " 'undefin',\n",
       " 'radiu',\n",
       " 'pi',\n",
       " 'parallel ',\n",
       " 'quarter',\n",
       " 'chord',\n",
       " 'circumfer',\n",
       " 'combin',\n",
       " 'empir',\n",
       " 'estim',\n",
       " 'expon',\n",
       " 'exponenti',\n",
       " 'frequenc',\n",
       " 'magnitud',\n",
       " 'matrix',\n",
       " 'opposit',\n",
       " 'ray',\n",
       " 'recurs',\n",
       " 'remain',\n",
       " 'rhombu',\n",
       " 'rotat',\n",
       " 'similar',\n",
       " 'statist',\n",
       " 'transform',\n",
       " 'trapezoid',\n",
       " 'trigonometri',\n",
       " 'vector',\n",
       " 'vari',\n",
       " 'sqrt',\n",
       " 'elimin',\n",
       " 'constant',\n",
       " 'frac',\n",
       " 'find',\n",
       " 'express',\n",
       " 'exp']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words=[stemm.stem(i) for i in lst]\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_MfD2vzSQ3K"
   },
   "source": [
    "**EXTRACTING MATH VOCAB WORDS FROM THE COLUMN 'Problem'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fractional|product|solve|equation|expression|rate|total|evaluate|compute|maximum|percent|arithmetic|sequence|integers|positive|distance|difference|how many|sum|square|cube|absolute value|cost|simplify|real number|what is the value|how much|operation|calculate|formula|positive integer|price|draw|length|subtract|lattice|largest|smallest|greatest number|equal|line|increase|multiple|average|number|divide|area|median|remainder|add|different|triange|equilateral|perimeter|size|angle|degree|measure|probability|segment|randomly chosen|prime number|random selection|randomly selected|digit|exact|paranethesis|obtuse|interior angle|ratio|range|multiply|function|domain|common fraction|hyperbola|graph|roots|even|odd|complex|plane|mid-point|conjugate|radicale|polynomial|interval|lowest|midpoint|consecutive|preceding|times|slope|endpoint|coordinate|proportional|reciprocal|numerator|denominator|set|inverse|simplest|intersection|point|intercept|cooefficient|ordered|inclusive|exclusive|vertices|altogether|together|decrease|successive|rectangle|diagonal|width|height|factor|circle|volume|cartesian|geometric|log|nearest|decimal|solution|amount|rationalize|more than|less than|more|less|count|find|binomial|common fractor|horizontal|vertical|polygon|greater than|divisor|parallelogram|complement|divisible|equally likely|reduce|distinct|adjacent|perpendicular|remove|randomly|older|newer|mean|whole number|at least|atmost|distribution|supplementary|symbols|exceed|ellipse|asymptote|sign|parabola|union|quotient|tangent|harmonic|oblique|symmetric|axis|variable|quadratic|improper fraction|proper fraction|straight line|discriminant|nonzero|diagram|progression|diameter|center|discount|infinite|undefined|radius|pi|parallel |quarter|chord|circumference|combine|empirical|estimate|exponent|exponential|frequency|magnitude|matrix|opposite|ray|recursive|remaining|rhombus|rotation|similarity|statistics|transformation|trapezoid|trigonometry|vector|varies|sqrt|eliminate|constants|frac|find|express|exp'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '|'.join(lst)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pIdO0Y9IKpY",
    "outputId": "eda1baa4-d5b7-4176-ae06-9e774b230e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Problem   Level   \\\n",
      "0     there are constants    alpha  and    beta  suc...       5   \n",
      "1     the length of the segment between the points  ...       5   \n",
      "2     chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
      "3     for some constants  a  and  b,  let   [f(x) = ...       5   \n",
      "4     calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
      "...                                                 ...     ...   \n",
      "1739  what is the slope of the line passing through ...       2   \n",
      "1740  evaluate  i^{11} + i^{16} + i^{21} + i^{26} + ...       4   \n",
      "1741  if  a  is a constant such that  4x^2 - 12x + a...       3   \n",
      "1742  given  a   star b = a^2 + 2ab + b^2 , what is ...       3   \n",
      "1743  the graph of the function  f(x)  is shown belo...       5   \n",
      "\n",
      "                                                   word  \n",
      "0                               [constants, frac, frac]  \n",
      "1                      [length, segment, sqrt, product]  \n",
      "2                         [ratio, number, number, find]  \n",
      "3                                 [constants, function]  \n",
      "4                                      [calculate, sum]  \n",
      "...                                                 ...  \n",
      "1739                                      [slope, line]  \n",
      "1740                                         [evaluate]  \n",
      "1741                                 [square, binomial]  \n",
      "1742                                [what is the value]  \n",
      "1743  [graph, function, how many, graph, size, draw,...  \n",
      "\n",
      "[1744 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df['word'] = df['Problem '].str.findall(r'\\b({})\\b'.format(query)) \n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ud2AlDXXIUjl"
   },
   "outputs": [],
   "source": [
    "df['Mword_count']=df['word'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "cnxxhazcIXry",
    "outputId": "fa88a137-3cd1-4fe2-d76a-d40241244be9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \n",
       "0           [constants, frac, frac]            3  \n",
       "1  [length, segment, sqrt, product]            4  \n",
       "2     [ratio, number, number, find]            4  \n",
       "3             [constants, function]            2  \n",
       "4                  [calculate, sum]            2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equations_count(expression):\n",
    "  regexes = [r\"\\$\\$([^$]+)\\$\\$\", r\"\\$([^$]+)\\$\", r\"\\\\\\(([^$]+)\\\\\\)\", r\"\\\\\\[([^$]+)\\\\\\]\"]\n",
    "  no_of_equations = 0\n",
    "  for regex in regexes:\n",
    "    matches = re.findall(regex, expression)\n",
    "    no_of_equations += len(matches)\n",
    "    expression = re.sub(regex, \"\", expression)\n",
    "  return pd.Series({'modified_problem':expression})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df['Problem '].apply(get_equations_count)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>modified_problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \\\n",
       "0           [constants, frac, frac]            3   \n",
       "1  [length, segment, sqrt, product]            4   \n",
       "2     [ratio, number, number, find]            4   \n",
       "3             [constants, function]            2   \n",
       "4                  [calculate, sum]            2   \n",
       "\n",
       "                                    modified_problem  \n",
       "0  there are constants    alpha  and    beta  suc...  \n",
       "1  the length of the segment between the points  ...  \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...  \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...  \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there are constants    alpha  and    beta  such that    frac{x-  alpha}{x+  beta} =   frac{x^2-80x+1551}{x^2+57x-2970} . what is    alpha+  beta ?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'modified_problem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fek4PXg8thfo"
   },
   "source": [
    "**mathword_count = TMVW** (total math vocab words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Uc5VmpQzIjdg"
   },
   "outputs": [],
   "source": [
    "# def word_length(df_col):\n",
    "#   number_of_words = len(df_col.split())\n",
    "#   # print(df_col.split())\n",
    "#   return number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "yP5z6b2LItHF"
   },
   "outputs": [],
   "source": [
    "#df_liststring['mathword_count'] = df_liststring['liststring'].apply(word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3uquq1VTdmk"
   },
   "source": [
    "**FUNCTION TO COUNT THE TOTAL NUMBER OF SENTENCES IN EACH MATH WORD PROBLEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pawan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xAt7MpQFIx7w"
   },
   "outputs": [],
   "source": [
    "def count_sentences(data):\n",
    "  number_of_sentences = sent_tokenize(data)\n",
    "  return len(number_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "REM68N6bJM2v"
   },
   "outputs": [],
   "source": [
    "df['countsent'] = df['modified_problem'].apply(count_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qh-NqCuzJM87",
    "outputId": "eb8efbd3-a53a-403a-8776-123e558504f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>modified_problem</th>\n",
       "      <th>countsent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \\\n",
       "0           [constants, frac, frac]            3   \n",
       "1  [length, segment, sqrt, product]            4   \n",
       "2     [ratio, number, number, find]            4   \n",
       "3             [constants, function]            2   \n",
       "4                  [calculate, sum]            2   \n",
       "\n",
       "                                    modified_problem  countsent  \n",
       "0  there are constants    alpha  and    beta  suc...          2  \n",
       "1  the length of the segment between the points  ...          2  \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...          5  \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...          2  \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...          1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GYO9QyWTqI8"
   },
   "source": [
    "**FUNCTION TO COUNT ALL NUMBER OF WORDS IN EACH MATH PROBLEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_ravrkLxJNAB"
   },
   "outputs": [],
   "source": [
    "def count_allwords(data):\n",
    "  number_of_words = len(data.split())\n",
    "  return number_of_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Ydp7RlOGJgmQ"
   },
   "outputs": [],
   "source": [
    "df['allwords'] = df['Problem '].apply(count_allwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2ppNSOO-JpZZ",
    "outputId": "a238ccf8-b1bd-415b-e596-3195465b03aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>modified_problem</th>\n",
       "      <th>countsent</th>\n",
       "      <th>allwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \\\n",
       "0           [constants, frac, frac]            3   \n",
       "1  [length, segment, sqrt, product]            4   \n",
       "2     [ratio, number, number, find]            4   \n",
       "3             [constants, function]            2   \n",
       "4                  [calculate, sum]            2   \n",
       "\n",
       "                                    modified_problem  countsent  allwords  \n",
       "0  there are constants    alpha  and    beta  suc...          2        19  \n",
       "1  the length of the segment between the points  ...          2        28  \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...          5        81  \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...          2        50  \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...          1        15  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRpHPihVT7Sf"
   },
   "source": [
    "**FUNCTION TO COUNT THE MATH SYMBOLS IN EACH WORD PROBLEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "w-Mkm0m3NMMn"
   },
   "outputs": [],
   "source": [
    "math_symbols = []\n",
    "l = \"!@#$%^&*()-[]{}:;<>+=-/?.,\"\n",
    "for i in l:\n",
    "  math_symbols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_Iycr5obNUH0"
   },
   "outputs": [],
   "source": [
    "\n",
    "def count_symbols(data):\n",
    "  total_count = 0\n",
    "  data = data.split()\n",
    "  for word in data: \n",
    "    if word in math_symbols:\n",
    "      total_count = total_count+1\n",
    "  return total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "dtpHOnPLNXms"
   },
   "outputs": [],
   "source": [
    "df['symbols'] = df['Problem '].apply(count_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ISAdaL8rNe-T",
    "outputId": "721062ee-dc15-486a-acd1-13d5accff49f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>modified_problem</th>\n",
       "      <th>countsent</th>\n",
       "      <th>allwords</th>\n",
       "      <th>symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \\\n",
       "0           [constants, frac, frac]            3   \n",
       "1  [length, segment, sqrt, product]            4   \n",
       "2     [ratio, number, number, find]            4   \n",
       "3             [constants, function]            2   \n",
       "4                  [calculate, sum]            2   \n",
       "\n",
       "                                    modified_problem  countsent  allwords  \\\n",
       "0  there are constants    alpha  and    beta  suc...          2        19   \n",
       "1  the length of the segment between the points  ...          2        28   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...          5        81   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...          2        50   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...          1        15   \n",
       "\n",
       "   symbols  \n",
       "0        3  \n",
       "1        1  \n",
       "2        1  \n",
       "3       11  \n",
       "4        6  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHFMVNE7UDMw"
   },
   "source": [
    "**FUNCTION TO COUNT THE NUMBERS IN EACH MATH WORD PROBLEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "bs32BHyVNkCN"
   },
   "outputs": [],
   "source": [
    "def count_nums(data):\n",
    "  total_count = 0\n",
    "  data = data.split()\n",
    "  for word in data: \n",
    "    if word.isalpha() == False:\n",
    "      total_count = total_count+1\n",
    "  return total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "1uynJbAvNsBs"
   },
   "outputs": [],
   "source": [
    "df['numbers'] = df['Problem '].apply(count_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vlPuJDdFNyPJ",
    "outputId": "ee92b58e-86bc-4d88-d982-6233b350a3ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>modified_problem</th>\n",
       "      <th>countsent</th>\n",
       "      <th>allwords</th>\n",
       "      <th>symbols</th>\n",
       "      <th>numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \\\n",
       "0           [constants, frac, frac]            3   \n",
       "1  [length, segment, sqrt, product]            4   \n",
       "2     [ratio, number, number, find]            4   \n",
       "3             [constants, function]            2   \n",
       "4                  [calculate, sum]            2   \n",
       "\n",
       "                                    modified_problem  countsent  allwords  \\\n",
       "0  there are constants    alpha  and    beta  suc...          2        19   \n",
       "1  the length of the segment between the points  ...          2        28   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...          5        81   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...          2        50   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...          1        15   \n",
       "\n",
       "   symbols  numbers  \n",
       "0        3        8  \n",
       "1        1        8  \n",
       "2        1       10  \n",
       "3       11       26  \n",
       "4        6       11  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJoFgZacUY3F"
   },
   "source": [
    "**COUNT OF MATH VOCAB WORD IN EACH SENTENCE ('mathword_count'/'countsent')**\n",
    "* TOTAL MATH VOCAB IN PROBLEM/NUMBER OF SENTENCES IN PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "D82TaESqWOSn",
    "outputId": "6b5e4325-10c6-4150-b1d6-0acef6df83b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>modified_problem</th>\n",
       "      <th>countsent</th>\n",
       "      <th>allwords</th>\n",
       "      <th>symbols</th>\n",
       "      <th>numbers</th>\n",
       "      <th>mathprop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \\\n",
       "0           [constants, frac, frac]            3   \n",
       "1  [length, segment, sqrt, product]            4   \n",
       "2     [ratio, number, number, find]            4   \n",
       "3             [constants, function]            2   \n",
       "4                  [calculate, sum]            2   \n",
       "\n",
       "                                    modified_problem  countsent  allwords  \\\n",
       "0  there are constants    alpha  and    beta  suc...          2        19   \n",
       "1  the length of the segment between the points  ...          2        28   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...          5        81   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...          2        50   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...          1        15   \n",
       "\n",
       "   symbols  numbers  mathprop  \n",
       "0        3        8       1.5  \n",
       "1        1        8       2.0  \n",
       "2        1       10       0.8  \n",
       "3       11       26       1.0  \n",
       "4        6       11       2.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mathprop'] = df['Mword_count']/df['countsent']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRku62boxqHg"
   },
   "source": [
    "FUNCTION FOR CALCULATING NUMBER OF (CHARACTERS) IN WORD PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "7pNLVsppweB9"
   },
   "outputs": [],
   "source": [
    "def count_chars(df_col):\n",
    "  count = 0\n",
    "  for i in df_col:\n",
    "    for j in i:\n",
    "      count = count+1\n",
    "  return count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "EzpSZ132weCH"
   },
   "outputs": [],
   "source": [
    "df['char_sum'] = df['modified_problem'].apply(count_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there are constants    alpha  and    beta  such that    frac{x-  alpha}{x+  beta} =   frac{x^2-80x+1551}{x^2+57x-2970} . what is    alpha+  beta ?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,\"modified_problem\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7-dbCmAzJJl"
   },
   "source": [
    "**word_sum = CMVW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0v3Tha5zweCI",
    "outputId": "bbfe4dc2-1d92-4405-8dfa-95eb2db38ac3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>modified_problem</th>\n",
       "      <th>countsent</th>\n",
       "      <th>allwords</th>\n",
       "      <th>symbols</th>\n",
       "      <th>numbers</th>\n",
       "      <th>mathprop</th>\n",
       "      <th>char_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \\\n",
       "0           [constants, frac, frac]            3   \n",
       "1  [length, segment, sqrt, product]            4   \n",
       "2     [ratio, number, number, find]            4   \n",
       "3             [constants, function]            2   \n",
       "4                  [calculate, sum]            2   \n",
       "\n",
       "                                    modified_problem  countsent  allwords  \\\n",
       "0  there are constants    alpha  and    beta  suc...          2        19   \n",
       "1  the length of the segment between the points  ...          2        28   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...          5        81   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...          2        50   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...          1        15   \n",
       "\n",
       "   symbols  numbers  mathprop  char_sum  \n",
       "0        3        8       1.5       146  \n",
       "1        1        8       2.0       146  \n",
       "2        1       10       0.8       404  \n",
       "3       11       26       1.0       245  \n",
       "4        6       11       2.0        50  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_words(mwl_col):\n",
    "    words = mwl_col.split()\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if len(word) > 6:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "aMceJqDfN0DO"
   },
   "outputs": [],
   "source": [
    "WordsPerSentence = []\n",
    "#MathWordsPerSentence = []\n",
    "MathSymbolsPerSentence = [] \n",
    "NumCountPerSentence = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07jHfzdQU_WF"
   },
   "source": [
    "**CALCULATION OF:**\n",
    "1. WordsPerSentence\n",
    "2. MathSymbolsPerSentence\n",
    "3. NumCountPerSentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "KwwGgSxxOR3y"
   },
   "outputs": [],
   "source": [
    "for i in df.iloc[:,0]:\n",
    "  s = count_sentences(i)\n",
    "  w = count_allwords(i)\n",
    "  ms = count_symbols(i)\n",
    "  n = count_nums(i) \n",
    "  #mw = word_length(i)\n",
    "\n",
    "  WordsPerSentence.append(w/s)  \n",
    "  MathSymbolsPerSentence.append(ms/s)   \n",
    "  NumCountPerSentence.append(n/s)  \n",
    "  #MathWordsPerSentence.append(mw/s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame() \n",
    "df_data[\"WordsPerSentence\"] = WordsPerSentence\n",
    "df_data[\"MathSymbolsPerSentence\"] = MathSymbolsPerSentence\n",
    "df_data[\"NumCountPerSentence\"] = NumCountPerSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>modified_problem</th>\n",
       "      <th>countsent</th>\n",
       "      <th>allwords</th>\n",
       "      <th>symbols</th>\n",
       "      <th>numbers</th>\n",
       "      <th>mathprop</th>\n",
       "      <th>char_sum</th>\n",
       "      <th>WordsPerSentence</th>\n",
       "      <th>MathSymbolsPerSentence</th>\n",
       "      <th>NumCountPerSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>146</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>404</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>245</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \\\n",
       "0           [constants, frac, frac]            3   \n",
       "1  [length, segment, sqrt, product]            4   \n",
       "2     [ratio, number, number, find]            4   \n",
       "3             [constants, function]            2   \n",
       "4                  [calculate, sum]            2   \n",
       "\n",
       "                                    modified_problem  countsent  allwords  \\\n",
       "0  there are constants    alpha  and    beta  suc...          2        19   \n",
       "1  the length of the segment between the points  ...          2        28   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...          5        81   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...          2        50   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...          1        15   \n",
       "\n",
       "   symbols  numbers  mathprop  char_sum  WordsPerSentence  \\\n",
       "0        3        8       1.5       146               9.5   \n",
       "1        1        8       2.0       146              14.0   \n",
       "2        1       10       0.8       404              16.2   \n",
       "3       11       26       1.0       245              25.0   \n",
       "4        6       11       2.0        50              15.0   \n",
       "\n",
       "   MathSymbolsPerSentence  NumCountPerSentence  \n",
       "0                     1.5                  4.0  \n",
       "1                     0.5                  4.0  \n",
       "2                     0.2                  2.0  \n",
       "3                     5.5                 13.0  \n",
       "4                     6.0                 11.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data=pd.concat([df,df_data],axis=1)\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTut7fyn5MbU"
   },
   "source": [
    "**FUNCTION TO COUNT SYLLABLES IN EACH WORD PROBLEM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fs0J--il5U5h"
   },
   "source": [
    "**Counted number of syllables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "baUkHGE1X-iU"
   },
   "outputs": [],
   "source": [
    "def syllable_count(df_col):\n",
    "    df_col = df_col.lower()\n",
    "    count = 0\n",
    "    vowels = \"aeiou\"\n",
    "    if df_col[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(df_col)):\n",
    "        if df_col[index] in vowels and df_col[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if df_col.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-hzCMVh15Lpx"
   },
   "outputs": [],
   "source": [
    "df_data['syllables'] = df_data['Problem '].apply(syllable_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "BMNKL5BR5Ls8",
    "outputId": "ba6ccae8-eebf-49ad-9bbf-c5f0c7ac158b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>modified_problem</th>\n",
       "      <th>countsent</th>\n",
       "      <th>allwords</th>\n",
       "      <th>symbols</th>\n",
       "      <th>numbers</th>\n",
       "      <th>mathprop</th>\n",
       "      <th>char_sum</th>\n",
       "      <th>WordsPerSentence</th>\n",
       "      <th>MathSymbolsPerSentence</th>\n",
       "      <th>NumCountPerSentence</th>\n",
       "      <th>syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>146</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>404</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>245</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \\\n",
       "0           [constants, frac, frac]            3   \n",
       "1  [length, segment, sqrt, product]            4   \n",
       "2     [ratio, number, number, find]            4   \n",
       "3             [constants, function]            2   \n",
       "4                  [calculate, sum]            2   \n",
       "\n",
       "                                    modified_problem  countsent  allwords  \\\n",
       "0  there are constants    alpha  and    beta  suc...          2        19   \n",
       "1  the length of the segment between the points  ...          2        28   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...          5        81   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...          2        50   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...          1        15   \n",
       "\n",
       "   symbols  numbers  mathprop  char_sum  WordsPerSentence  \\\n",
       "0        3        8       1.5       146               9.5   \n",
       "1        1        8       2.0       146              14.0   \n",
       "2        1       10       0.8       404              16.2   \n",
       "3       11       26       1.0       245              25.0   \n",
       "4        6       11       2.0        50              15.0   \n",
       "\n",
       "   MathSymbolsPerSentence  NumCountPerSentence  syllables  \n",
       "0                     1.5                  4.0         25  \n",
       "1                     0.5                  4.0         30  \n",
       "2                     0.2                  2.0        107  \n",
       "3                     5.5                 13.0         36  \n",
       "4                     6.0                 11.0          7  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8SegGi67bkq"
   },
   "source": [
    "**FUNCTION TO COUNT OF POLY SYLLABLES IN EACH WORD PROBLEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Yy7PimsR5Lvg"
   },
   "outputs": [],
   "source": [
    "def count_poly_syllables(df_col):\n",
    "  total_count = 0\n",
    "  df_col = df_col.split()\n",
    "  for word in df_col: \n",
    "    #print(word)\n",
    "    temp = syllable_count(word)\n",
    "    if temp>=3:\n",
    "      total_count = total_count+temp\n",
    "  return total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "BL9xK3rx5LyD"
   },
   "outputs": [],
   "source": [
    "df_data['poly_syllables'] = df_data['Problem '].apply(count_poly_syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "jBTgPvFf5L0I",
    "outputId": "5163f503-2725-4fe1-a534-f04a6b831708"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem</th>\n",
       "      <th>Level</th>\n",
       "      <th>word</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>modified_problem</th>\n",
       "      <th>countsent</th>\n",
       "      <th>allwords</th>\n",
       "      <th>symbols</th>\n",
       "      <th>numbers</th>\n",
       "      <th>mathprop</th>\n",
       "      <th>char_sum</th>\n",
       "      <th>WordsPerSentence</th>\n",
       "      <th>MathSymbolsPerSentence</th>\n",
       "      <th>NumCountPerSentence</th>\n",
       "      <th>syllables</th>\n",
       "      <th>poly_syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, frac, frac]</td>\n",
       "      <td>3</td>\n",
       "      <td>there are constants    alpha  and    beta  suc...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>146</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[length, segment, sqrt, product]</td>\n",
       "      <td>4</td>\n",
       "      <td>the length of the segment between the points  ...</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[ratio, number, number, find]</td>\n",
       "      <td>4</td>\n",
       "      <td>chewbacca has 20 pieces of cherry gum and 30 p...</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>404</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[constants, function]</td>\n",
       "      <td>2</td>\n",
       "      <td>for some constants  a  and  b,  let   [f(x) = ...</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>245</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[calculate, sum]</td>\n",
       "      <td>2</td>\n",
       "      <td>calculate the sum  1 + 3 + 5 +   cdots + 15 + ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Problem   Level   \\\n",
       "0  there are constants    alpha  and    beta  suc...       5   \n",
       "1  the length of the segment between the points  ...       5   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...       5   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...       5   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...       2   \n",
       "\n",
       "                               word  Mword_count  \\\n",
       "0           [constants, frac, frac]            3   \n",
       "1  [length, segment, sqrt, product]            4   \n",
       "2     [ratio, number, number, find]            4   \n",
       "3             [constants, function]            2   \n",
       "4                  [calculate, sum]            2   \n",
       "\n",
       "                                    modified_problem  countsent  allwords  \\\n",
       "0  there are constants    alpha  and    beta  suc...          2        19   \n",
       "1  the length of the segment between the points  ...          2        28   \n",
       "2  chewbacca has 20 pieces of cherry gum and 30 p...          5        81   \n",
       "3  for some constants  a  and  b,  let   [f(x) = ...          2        50   \n",
       "4  calculate the sum  1 + 3 + 5 +   cdots + 15 + ...          1        15   \n",
       "\n",
       "   symbols  numbers  mathprop  char_sum  WordsPerSentence  \\\n",
       "0        3        8       1.5       146               9.5   \n",
       "1        1        8       2.0       146              14.0   \n",
       "2        1       10       0.8       404              16.2   \n",
       "3       11       26       1.0       245              25.0   \n",
       "4        6       11       2.0        50              15.0   \n",
       "\n",
       "   MathSymbolsPerSentence  NumCountPerSentence  syllables  poly_syllables  \n",
       "0                     1.5                  4.0         25               0  \n",
       "1                     0.5                  4.0         30               0  \n",
       "2                     0.2                  2.0        107               6  \n",
       "3                     5.5                 13.0         36               7  \n",
       "4                     6.0                 11.0          7               3  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJgtOa75986o"
   },
   "source": [
    "1. count_sentences = number of sentences in word Problem\n",
    "2. count_allwords = all words in word Problem\n",
    "3. count_symbols = math symbols in word Problem\n",
    "4. count_nums = count numbers in word Problem\n",
    "5. syllable_count = number of syllables in word problem\n",
    "6. count_poly_syllables = number of poly syllables in word problem\n",
    "7. count_char = total characters in word Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Use only math scores to predict the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Problem ', 'Level ', 'word', 'Mword_count', 'modified_problem',\n",
       "       'countsent', 'allwords', 'symbols', 'numbers', 'mathprop', 'char_sum',\n",
       "       'WordsPerSentence', 'MathSymbolsPerSentence', 'NumCountPerSentence',\n",
       "       'syllables', 'poly_syllables'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>mathprop</th>\n",
       "      <th>MathSymbolsPerSentence</th>\n",
       "      <th>NumCountPerSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level   Mword_count  mathprop  MathSymbolsPerSentence  NumCountPerSentence\n",
       "0       5            3       1.5                     1.5                  4.0\n",
       "1       5            4       2.0                     0.5                  4.0\n",
       "2       5            4       0.8                     0.2                  2.0\n",
       "3       5            2       1.0                     5.5                 13.0\n",
       "4       2            2       2.0                     6.0                 11.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Required data\n",
    "cols=['Level ','Mword_count','mathprop','MathSymbolsPerSentence','NumCountPerSentence']\n",
    "math_data=df_data[cols]\n",
    "math_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### \n",
    "X_train,X_test,y_train,y_test=train_test_split(math_data.iloc[:,1:],math_data.iloc[:,0],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    349\n",
      "4    320\n",
      "3    314\n",
      "2    275\n",
      "1    137\n",
      "Name: Level , dtype: int64\n",
      "\n",
      "\n",
      "3    669\n",
      "1    412\n",
      "2    314\n",
      "Name: Level , dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y1_train=y_train.replace({2:1,3:2,4:3,5:3})\n",
    "print(y_train.value_counts())\n",
    "print(\"\\n\")\n",
    "print(y1_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test=y_test.replace({2:1,3:2,4:3,5:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', max_depth=5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test on 5 levels\n",
    "mod_dt=DecisionTreeClassifier(class_weight='balanced',max_depth=5)\n",
    "mod_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.71      0.32       137\n",
      "           2       0.36      0.23      0.28       275\n",
      "           3       0.48      0.11      0.18       314\n",
      "           4       0.40      0.18      0.25       320\n",
      "           5       0.40      0.61      0.48       349\n",
      "\n",
      "    accuracy                           0.33      1395\n",
      "   macro avg       0.37      0.37      0.30      1395\n",
      "weighted avg       0.39      0.33      0.31      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.68      0.36        41\n",
      "           2       0.30      0.25      0.27        65\n",
      "           3       0.29      0.09      0.14        78\n",
      "           4       0.38      0.12      0.18        78\n",
      "           5       0.33      0.49      0.39        87\n",
      "\n",
      "    accuracy                           0.30       349\n",
      "   macro avg       0.31      0.33      0.27       349\n",
      "weighted avg       0.31      0.30      0.26       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predictions\n",
    "tr_pred=mod_dt.predict(X_train)\n",
    "te_pred=mod_dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train,tr_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,te_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.58      0.52       412\n",
      "           2       0.36      0.37      0.37       314\n",
      "           3       0.66      0.56      0.61       669\n",
      "\n",
      "    accuracy                           0.52      1395\n",
      "   macro avg       0.50      0.50      0.50      1395\n",
      "weighted avg       0.54      0.52      0.53      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.53      0.49       106\n",
      "           2       0.26      0.31      0.28        78\n",
      "           3       0.62      0.50      0.56       165\n",
      "\n",
      "    accuracy                           0.47       349\n",
      "   macro avg       0.45      0.45      0.44       349\n",
      "weighted avg       0.49      0.47      0.47       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### on 3 classes\n",
    "mod_dt=DecisionTreeClassifier(class_weight='balanced',max_depth=5)\n",
    "mod_dt.fit(X_train,y1_train)\n",
    "\n",
    "tr_pred=mod_dt.predict(X_train)\n",
    "te_pred=mod_dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y1_train,tr_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y1_test,te_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>mathprop</th>\n",
       "      <th>MathSymbolsPerSentence</th>\n",
       "      <th>NumCountPerSentence</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Mword_count  mathprop  MathSymbolsPerSentence  NumCountPerSentence  \\\n",
       "864             3       1.5                     0.5                  2.5   \n",
       "310             3       3.0                     4.0                  7.0   \n",
       "56              1       1.0                     3.0                 13.0   \n",
       "1736            4       2.0                     0.5                  2.0   \n",
       "1138            3       3.0                     1.0                  2.0   \n",
       "\n",
       "      Level   \n",
       "864        5  \n",
       "310        5  \n",
       "56         4  \n",
       "1736       5  \n",
       "1138       5  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Ordered Regression on 5 classes\n",
    "\n",
    "ord_data=pd.concat([X_train,y_train],axis=1)\n",
    "ord_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
       "       'NumCountPerSentence', 'Level '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.517891\n",
      "         Iterations: 19\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Level </td>       <th>  Log-Likelihood:    </th> <td> -2117.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>    <th>  AIC:               </th> <td>   4251.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   4293.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Tue, 13 Jun 2023</td>  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>22:33:02</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  1395</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  1387</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     8</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mword_count</th>            <td>    0.2628</td> <td>    0.031</td> <td>    8.542</td> <td> 0.000</td> <td>    0.203</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mathprop</th>               <td>   -0.0820</td> <td>    0.042</td> <td>   -1.933</td> <td> 0.053</td> <td>   -0.165</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MathSymbolsPerSentence</th> <td>    0.1109</td> <td>    0.040</td> <td>    2.765</td> <td> 0.006</td> <td>    0.032</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NumCountPerSentence</th>    <td>   -0.0139</td> <td>    0.018</td> <td>   -0.794</td> <td> 0.427</td> <td>   -0.048</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1/2</th>                    <td>   -1.4891</td> <td>    0.118</td> <td>  -12.570</td> <td> 0.000</td> <td>   -1.721</td> <td>   -1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2/3</th>                    <td>    0.3362</td> <td>    0.058</td> <td>    5.842</td> <td> 0.000</td> <td>    0.223</td> <td>    0.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3/4</th>                    <td>    0.0142</td> <td>    0.052</td> <td>    0.276</td> <td> 0.782</td> <td>   -0.087</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4/5</th>                    <td>    0.0940</td> <td>    0.051</td> <td>    1.828</td> <td> 0.068</td> <td>   -0.007</td> <td>    0.195</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OrderedModel Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:                 Level    Log-Likelihood:                -2117.5\n",
       "Model:                   OrderedModel   AIC:                             4251.\n",
       "Method:            Maximum Likelihood   BIC:                             4293.\n",
       "Date:                Tue, 13 Jun 2023                                         \n",
       "Time:                        22:33:02                                         \n",
       "No. Observations:                1395                                         \n",
       "Df Residuals:                    1387                                         \n",
       "Df Model:                           8                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Mword_count                0.2628      0.031      8.542      0.000       0.203       0.323\n",
       "mathprop                  -0.0820      0.042     -1.933      0.053      -0.165       0.001\n",
       "MathSymbolsPerSentence     0.1109      0.040      2.765      0.006       0.032       0.190\n",
       "NumCountPerSentence       -0.0139      0.018     -0.794      0.427      -0.048       0.020\n",
       "1/2                       -1.4891      0.118    -12.570      0.000      -1.721      -1.257\n",
       "2/3                        0.3362      0.058      5.842      0.000       0.223       0.449\n",
       "3/4                        0.0142      0.052      0.276      0.782      -0.087       0.115\n",
       "4/5                        0.0940      0.051      1.828      0.068      -0.007       0.195\n",
       "==========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the ordinal regression model\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "mod_ordered=OrderedModel(ord_data['Level '],ord_data[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence']],distr='logit',)\n",
    "\n",
    "res_log = mod_ordered.fit(method='bfgs')\n",
    "res_log.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_test=pd.concat([X_test,y_test],axis=1)\n",
    "pred_train=res_log.model.predict(res_log.params, exog=ord_data[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence']])\n",
    "pred_test=res_log.model.predict(res_log.params, exog=ord_test[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10199861, 0.21327975, 0.24413536, 0.23263098, 0.20795529],\n",
       "       [0.08488081, 0.18837814, 0.23578734, 0.24765908, 0.24329463],\n",
       "       [0.13922636, 0.25679409, 0.24786422, 0.2004416 , 0.15567373],\n",
       "       ...,\n",
       "       [0.1263276 , 0.243217  , 0.24824306, 0.21122986, 0.17098248],\n",
       "       [0.02602852, 0.07171664, 0.13227563, 0.24258613, 0.52739308],\n",
       "       [0.07273054, 0.1685216 , 0.22592328, 0.25735055, 0.27547403]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train1=np.argmax(pred_train, axis=1)+1\n",
    "pred_test1=np.argmax(pred_test, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       137\n",
      "           2       0.28      0.29      0.29       275\n",
      "           3       0.25      0.42      0.32       314\n",
      "           4       0.20      0.08      0.12       320\n",
      "           5       0.39      0.50      0.44       349\n",
      "\n",
      "    accuracy                           0.30      1395\n",
      "   macro avg       0.22      0.26      0.23      1395\n",
      "weighted avg       0.25      0.30      0.26      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ord_data['Level '],pred_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        41\n",
      "           2       0.24      0.22      0.23        65\n",
      "           3       0.23      0.44      0.30        78\n",
      "           4       0.26      0.08      0.12        78\n",
      "           5       0.38      0.53      0.44        87\n",
      "\n",
      "    accuracy                           0.29       349\n",
      "   macro avg       0.22      0.25      0.22       349\n",
      "weighted avg       0.25      0.29      0.25       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ord_test['Level '],pred_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for 3 levels\n",
    "ord_data1=pd.concat([X_train,y1_train],axis=1)\n",
    "ord_test1=pd.concat([X_test,y1_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.004994\n",
      "         Iterations: 18\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Level </td>       <th>  Log-Likelihood:    </th> <td> -1402.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>    <th>  AIC:               </th> <td>   2816.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   2847.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Tue, 13 Jun 2023</td>  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>22:33:02</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  1395</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  1389</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     6</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mword_count</th>            <td>    0.2824</td> <td>    0.037</td> <td>    7.654</td> <td> 0.000</td> <td>    0.210</td> <td>    0.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mathprop</th>               <td>   -0.0773</td> <td>    0.049</td> <td>   -1.563</td> <td> 0.118</td> <td>   -0.174</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MathSymbolsPerSentence</th> <td>    0.1345</td> <td>    0.043</td> <td>    3.102</td> <td> 0.002</td> <td>    0.050</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NumCountPerSentence</th>    <td>   -0.0262</td> <td>    0.019</td> <td>   -1.356</td> <td> 0.175</td> <td>   -0.064</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1/2</th>                    <td>   -0.0572</td> <td>    0.110</td> <td>   -0.519</td> <td> 0.604</td> <td>   -0.273</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2/3</th>                    <td>    0.0214</td> <td>    0.052</td> <td>    0.415</td> <td> 0.678</td> <td>   -0.080</td> <td>    0.122</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OrderedModel Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:                 Level    Log-Likelihood:                -1402.0\n",
       "Model:                   OrderedModel   AIC:                             2816.\n",
       "Method:            Maximum Likelihood   BIC:                             2847.\n",
       "Date:                Tue, 13 Jun 2023                                         \n",
       "Time:                        22:33:02                                         \n",
       "No. Observations:                1395                                         \n",
       "Df Residuals:                    1389                                         \n",
       "Df Model:                           6                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Mword_count                0.2824      0.037      7.654      0.000       0.210       0.355\n",
       "mathprop                  -0.0773      0.049     -1.563      0.118      -0.174       0.020\n",
       "MathSymbolsPerSentence     0.1345      0.043      3.102      0.002       0.050       0.220\n",
       "NumCountPerSentence       -0.0262      0.019     -1.356      0.175      -0.064       0.012\n",
       "1/2                       -0.0572      0.110     -0.519      0.604      -0.273       0.159\n",
       "2/3                        0.0214      0.052      0.415      0.678      -0.080       0.122\n",
       "==========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ordered=OrderedModel(ord_data1['Level '],ord_data1[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence']],distr='logit')\n",
    "\n",
    "res_log = mod_ordered.fit(method='bfgs')\n",
    "res_log.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=np.argmax(res_log.model.predict(res_log.params, exog=ord_data[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence']]),axis=1)+1\n",
    "pred_test=np.argmax(res_log.model.predict(res_log.params, exog=ord_test[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence']]),axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.40      0.44       412\n",
      "           2       0.00      0.00      0.00       314\n",
      "           3       0.54      0.86      0.66       669\n",
      "\n",
      "    accuracy                           0.53      1395\n",
      "   macro avg       0.35      0.42      0.37      1395\n",
      "weighted avg       0.41      0.53      0.45      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ord_data1['Level '],pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.32      0.37       106\n",
      "           2       0.00      0.00      0.00        78\n",
      "           3       0.52      0.86      0.65       165\n",
      "\n",
      "    accuracy                           0.50       349\n",
      "   macro avg       0.32      0.39      0.34       349\n",
      "weighted avg       0.38      0.50      0.42       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ord_test1['Level '],pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 1.9881 - accuracy: 0.2416\n",
      "Epoch 2/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6103 - accuracy: 0.2559\n",
      "Epoch 3/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5841 - accuracy: 0.2738\n",
      "Epoch 4/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5685 - accuracy: 0.2760\n",
      "Epoch 5/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5581 - accuracy: 0.2810\n",
      "Epoch 6/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5558 - accuracy: 0.2774\n",
      "Epoch 7/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5456 - accuracy: 0.2753\n",
      "Epoch 8/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5375 - accuracy: 0.2789\n",
      "Epoch 9/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5361 - accuracy: 0.2760\n",
      "Epoch 10/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5338 - accuracy: 0.2896\n",
      "Epoch 11/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5353 - accuracy: 0.2946\n",
      "Epoch 12/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5267 - accuracy: 0.3075\n",
      "Epoch 13/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5286 - accuracy: 0.2918\n",
      "Epoch 14/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5278 - accuracy: 0.2910\n",
      "Epoch 15/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5216 - accuracy: 0.2839\n",
      "Epoch 16/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5260 - accuracy: 0.2753\n",
      "Epoch 17/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5243 - accuracy: 0.2896\n",
      "Epoch 18/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5181 - accuracy: 0.2996\n",
      "Epoch 19/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5195 - accuracy: 0.2810\n",
      "Epoch 20/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5173 - accuracy: 0.2925\n",
      "Epoch 21/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5162 - accuracy: 0.2932\n",
      "Epoch 22/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5231 - accuracy: 0.2767\n",
      "Epoch 23/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5144 - accuracy: 0.2903\n",
      "Epoch 24/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5172 - accuracy: 0.2953\n",
      "Epoch 25/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5129 - accuracy: 0.2867\n",
      "Epoch 26/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5126 - accuracy: 0.3004\n",
      "Epoch 27/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5189 - accuracy: 0.2803\n",
      "Epoch 28/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5208 - accuracy: 0.2910\n",
      "Epoch 29/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5190 - accuracy: 0.2939\n",
      "Epoch 30/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5154 - accuracy: 0.3018\n",
      "Epoch 31/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5152 - accuracy: 0.2968\n",
      "Epoch 32/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5149 - accuracy: 0.2932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f2b215d60>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ANN on 5 levels\n",
    "y5_train=to_categorical(y_train)\n",
    "y5_test=to_categorical(y_test)\n",
    "\n",
    "y5_train=y5_train[:,1:]\n",
    "y5_test=y5_test[:,1:]\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_dim=4, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y5_train, epochs=32, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 4, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train=np.argmax(model.predict(X_train),axis=1)+1\n",
    "pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        41\n",
      "           2       0.24      0.32      0.27        65\n",
      "           3       0.00      0.00      0.00        78\n",
      "           4       0.19      0.18      0.18        78\n",
      "           5       0.33      0.69      0.45        87\n",
      "\n",
      "    accuracy                           0.27       349\n",
      "   macro avg       0.15      0.24      0.18       349\n",
      "weighted avg       0.17      0.27      0.20       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test=np.argmax(model.predict(X_test),axis=1)+1\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.12      0.19       137\n",
      "           2       0.26      0.34      0.30       275\n",
      "           3       0.00      0.00      0.00       314\n",
      "           4       0.26      0.24      0.25       320\n",
      "           5       0.35      0.71      0.47       349\n",
      "\n",
      "    accuracy                           0.31      1395\n",
      "   macro avg       0.27      0.28      0.24      1395\n",
      "weighted avg       0.25      0.31      0.25      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 1.2104 - accuracy: 0.3900\n",
      "Epoch 2/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0330 - accuracy: 0.4717\n",
      "Epoch 3/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0160 - accuracy: 0.4839\n",
      "Epoch 4/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0133 - accuracy: 0.4925\n",
      "Epoch 5/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0080 - accuracy: 0.4968\n",
      "Epoch 6/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0047 - accuracy: 0.5111\n",
      "Epoch 7/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0039 - accuracy: 0.5197\n",
      "Epoch 8/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0013 - accuracy: 0.5183\n",
      "Epoch 9/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0039 - accuracy: 0.5104\n",
      "Epoch 10/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9998 - accuracy: 0.5211\n",
      "Epoch 11/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9992 - accuracy: 0.5125\n",
      "Epoch 12/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9981 - accuracy: 0.5168\n",
      "Epoch 13/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9954 - accuracy: 0.5240\n",
      "Epoch 14/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9967 - accuracy: 0.5183\n",
      "Epoch 15/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9978 - accuracy: 0.5204\n",
      "Epoch 16/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9979 - accuracy: 0.5168\n",
      "Epoch 17/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9950 - accuracy: 0.5154\n",
      "Epoch 18/32\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.9946 - accuracy: 0.5240\n",
      "Epoch 19/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9938 - accuracy: 0.5312\n",
      "Epoch 20/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9913 - accuracy: 0.5147\n",
      "Epoch 21/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9926 - accuracy: 0.5247\n",
      "Epoch 22/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9936 - accuracy: 0.5254\n",
      "Epoch 23/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9921 - accuracy: 0.5319\n",
      "Epoch 24/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9930 - accuracy: 0.5204\n",
      "Epoch 25/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9923 - accuracy: 0.5190\n",
      "Epoch 26/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9923 - accuracy: 0.5247\n",
      "Epoch 27/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9895 - accuracy: 0.5269\n",
      "Epoch 28/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9882 - accuracy: 0.5283\n",
      "Epoch 29/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9894 - accuracy: 0.5326\n",
      "Epoch 30/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9892 - accuracy: 0.5211\n",
      "Epoch 31/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9885 - accuracy: 0.5276\n",
      "Epoch 32/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9896 - accuracy: 0.5290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f2b28a7c0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ANN\n",
    "####### on 3 levels\n",
    "y11_train=to_categorical(y1_train)\n",
    "y11_test=to_categorical(y1_test)\n",
    "\n",
    "y11_train=y11_train[:,1:]\n",
    "y11_test=y11_test[:,1:]\n",
    "\n",
    "model=Sequential()\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_dim=4, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y11_train, epochs=32, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_train=np.argmax(model.predict(X_train),axis=1)+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.41      0.44       106\n",
      "           2       0.00      0.00      0.00        78\n",
      "           3       0.54      0.85      0.66       165\n",
      "\n",
      "    accuracy                           0.52       349\n",
      "   macro avg       0.34      0.42      0.37       349\n",
      "weighted avg       0.40      0.52      0.45       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test=np.argmax(model.predict(X_test),axis=1)+1\n",
    "print(classification_report(y1_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.41      0.44       412\n",
      "           2       0.60      0.01      0.02       314\n",
      "           3       0.54      0.83      0.66       669\n",
      "\n",
      "    accuracy                           0.52      1395\n",
      "   macro avg       0.54      0.42      0.37      1395\n",
      "weighted avg       0.53      0.52      0.45      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1_train,pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Define the range of k values to evaluate\n",
    "k_values = range(2, 10)\n",
    "\n",
    "distortions = []\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=50)\n",
    "    kmeans.fit(X_train)\n",
    "    results.append(kmeans.labels_)\n",
    "    distortion = kmeans.inertia_\n",
    "    distortions.append(distortion)\n",
    "\n",
    "plt.plot(k_values, distortions, 'bx-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('Elbow Curve based on Math Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ARI: 0.9792887275899459\n"
     ]
    }
   ],
   "source": [
    "### Adjusted RandIndex\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "\n",
    "# Set the number of clusters for k-means\n",
    "n_clusters = 3\n",
    "\n",
    "cluster_labels = []\n",
    "all_labels = []\n",
    "num_runs = 10\n",
    "for _ in range(num_runs):\n",
    "    perturbed_data = X_train + np.random.normal(scale=0.01, size=X_train.shape)  # Perturb the data\n",
    "    labels = kmeans.fit_predict(perturbed_data)\n",
    "    cluster_labels.append(labels)\n",
    "\n",
    "# Calculate similarity scores (ARI) between clusters\n",
    "ari_scores = []\n",
    "for i in range(len(cluster_labels)):\n",
    "    for j in range(i+1, len(cluster_labels)):\n",
    "        ari = adjusted_rand_score(cluster_labels[i], cluster_labels[j])\n",
    "        ari_scores.append(ari)\n",
    "\n",
    "# Assess cluster stability using the similarity scores\n",
    "average_ari = np.mean(ari_scores)\n",
    "print(\"Average ARI:\", average_ari)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: RI English + math stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GunnigFox\n",
    "GF = []\n",
    "for i in df.iloc[:,0]:\n",
    "  w = count_allwords(i)\n",
    "  c = complex_words(i)\n",
    "  s = count_sentences(i)\n",
    "  gf_score = (w/s) + (100*c/w)\n",
    "  GF.append(0.4*gf_score)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formula: 206.835 - 1.015(total words/total sentences) - 84.6(total syllables/total words)\n",
    "FK = []\n",
    "for i in df.iloc[:,0]:\n",
    "  w = count_allwords(i)\n",
    "  syl = syllable_count(i)\n",
    "  s = count_sentences(i)\n",
    "  fk_score = (1.015*w/s) + (84.6*syl/w)\n",
    "  fk_score = 206.835 - fk_score \n",
    "  FK.append(fk_score)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fromula: 3.1291 + 1.0430(sqrt(number of polysyllables * 30 /number of sentences))\n",
    "SMOG = []\n",
    "for i in df.iloc[:,0]:\n",
    "  syl = count_poly_syllables(i)\n",
    "  s = count_sentences(i)\n",
    "  smog_score = np.sqrt(30*syl/s)\n",
    "  smog_score = smog_score * 1.0430\n",
    "  SMOG.append(3.1291+smog_score)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR = []\n",
    "for i in df.iloc[:,0]:\n",
    "  w = count_allwords(i)\n",
    "  c = count_chars(i)\n",
    "  s = count_sentences(i)\n",
    "  ar_score = (4.71*c/w) + (0.5*w/s) - 21.43\n",
    "  AR.append(ar_score)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formula: 0.0588(Avg characters per 100 words) - 15.8 - 0.296(average number of sentences per 100 words)\n",
    "CL = []\n",
    "for i in df.iloc[:,0]:\n",
    "  w = count_allwords(i)\n",
    "  c = count_chars(i)\n",
    "  s = count_sentences(i)\n",
    "  term1 = 0.0588*c*100/w #c:w :: ?:100\n",
    "  term3 = 0.296*s*100/w #s:w :: ?:100\n",
    "  cl_score = term1-15.8-term3\n",
    "  CL.append(cl_score)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "RI=pd.DataFrame({\"GF\":GF,\"FK\":FK,\"SMOG\":SMOG,\"AR\":AR,\"CL\":CL})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>mathprop</th>\n",
       "      <th>MathSymbolsPerSentence</th>\n",
       "      <th>NumCountPerSentence</th>\n",
       "      <th>GF</th>\n",
       "      <th>FK</th>\n",
       "      <th>SMOG</th>\n",
       "      <th>AR</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.221053</td>\n",
       "      <td>85.876711</td>\n",
       "      <td>3.129100</td>\n",
       "      <td>19.512632</td>\n",
       "      <td>26.267368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.742857</td>\n",
       "      <td>101.982143</td>\n",
       "      <td>3.129100</td>\n",
       "      <td>10.129286</td>\n",
       "      <td>12.745714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.936790</td>\n",
       "      <td>78.636444</td>\n",
       "      <td>9.387100</td>\n",
       "      <td>10.161852</td>\n",
       "      <td>11.700247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>120.548000</td>\n",
       "      <td>13.816670</td>\n",
       "      <td>14.149000</td>\n",
       "      <td>11.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>152.130000</td>\n",
       "      <td>13.023867</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>1.826667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level   Mword_count  mathprop  MathSymbolsPerSentence  NumCountPerSentence  \\\n",
       "0       5            3       1.5                     1.5                  4.0   \n",
       "1       5            4       2.0                     0.5                  4.0   \n",
       "2       5            4       0.8                     0.2                  2.0   \n",
       "3       5            2       1.0                     5.5                 13.0   \n",
       "4       2            2       2.0                     6.0                 11.0   \n",
       "\n",
       "          GF          FK       SMOG         AR         CL  \n",
       "0  12.221053   85.876711   3.129100  19.512632  26.267368  \n",
       "1  12.742857  101.982143   3.129100  10.129286  12.745714  \n",
       "2   9.936790   78.636444   9.387100  10.161852  11.700247  \n",
       "3  16.400000  120.548000  13.816670  14.149000  11.828000  \n",
       "4   8.666667  152.130000  13.023867   1.770000   1.826667  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RI_Math_data= pd.concat([math_data,RI],axis=1)\n",
    "RI_Math_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GF</th>\n",
       "      <th>FK</th>\n",
       "      <th>SMOG</th>\n",
       "      <th>AR</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.615896</td>\n",
       "      <td>0.599930</td>\n",
       "      <td>0.832686</td>\n",
       "      <td>0.722784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FK</th>\n",
       "      <td>-0.615896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.760914</td>\n",
       "      <td>-0.626928</td>\n",
       "      <td>-0.540520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOG</th>\n",
       "      <td>0.599930</td>\n",
       "      <td>-0.760914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577573</td>\n",
       "      <td>0.394300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>0.832686</td>\n",
       "      <td>-0.626928</td>\n",
       "      <td>0.577573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL</th>\n",
       "      <td>0.722784</td>\n",
       "      <td>-0.540520</td>\n",
       "      <td>0.394300</td>\n",
       "      <td>0.912156</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GF        FK      SMOG        AR        CL\n",
       "GF    1.000000 -0.615896  0.599930  0.832686  0.722784\n",
       "FK   -0.615896  1.000000 -0.760914 -0.626928 -0.540520\n",
       "SMOG  0.599930 -0.760914  1.000000  0.577573  0.394300\n",
       "AR    0.832686 -0.626928  0.577573  1.000000  0.912156\n",
       "CL    0.722784 -0.540520  0.394300  0.912156  1.000000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RI_Math_data.loc[:,[\"GF\",\"FK\",\"SMOG\",\"AR\",\"CL\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Models\n",
    "X_train,X_test,y_train,y_test=train_test_split(RI_Math_data.iloc[:,1:],RI_Math_data.iloc[:,0],test_size=0.2,random_state=42)\n",
    "y1_train=y_train.replace({2:1,3:2,4:3,5:3})\n",
    "y1_test=y_test.replace({2:1,3:2,4:3,5:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mword_count</th>\n",
       "      <th>mathprop</th>\n",
       "      <th>MathSymbolsPerSentence</th>\n",
       "      <th>NumCountPerSentence</th>\n",
       "      <th>GF</th>\n",
       "      <th>FK</th>\n",
       "      <th>SMOG</th>\n",
       "      <th>AR</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>99.395000</td>\n",
       "      <td>10.125757</td>\n",
       "      <td>8.533000</td>\n",
       "      <td>12.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>154.385000</td>\n",
       "      <td>3.129100</td>\n",
       "      <td>10.888000</td>\n",
       "      <td>15.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.021053</td>\n",
       "      <td>138.571053</td>\n",
       "      <td>17.122413</td>\n",
       "      <td>16.330000</td>\n",
       "      <td>17.922105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.490909</td>\n",
       "      <td>91.842727</td>\n",
       "      <td>13.023867</td>\n",
       "      <td>10.189091</td>\n",
       "      <td>14.116364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>103.005000</td>\n",
       "      <td>14.554593</td>\n",
       "      <td>8.905000</td>\n",
       "      <td>12.113333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Mword_count  mathprop  MathSymbolsPerSentence  NumCountPerSentence  \\\n",
       "864             3       1.5                     0.5                  2.5   \n",
       "310             3       3.0                     4.0                  7.0   \n",
       "56              1       1.0                     3.0                 13.0   \n",
       "1736            4       2.0                     0.5                  2.0   \n",
       "1138            3       3.0                     1.0                  2.0   \n",
       "\n",
       "             GF          FK       SMOG         AR         CL  \n",
       "864   12.000000   99.395000  10.125757   8.533000  12.404000  \n",
       "310   12.000000  154.385000   3.129100  10.888000  15.344000  \n",
       "56    16.021053  138.571053  17.122413  16.330000  17.922105  \n",
       "1736  13.490909   91.842727  13.023867  10.189091  14.116364  \n",
       "1138  11.466667  103.005000  14.554593   8.905000  12.113333  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', max_depth=5)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test on 5 levels\n",
    "mod_dt=DecisionTreeClassifier(class_weight='balanced',max_depth=5)\n",
    "mod_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.51      0.45       137\n",
      "           2       0.26      0.37      0.31       275\n",
      "           3       0.57      0.12      0.20       314\n",
      "           4       0.35      0.13      0.19       320\n",
      "           5       0.38      0.69      0.49       349\n",
      "\n",
      "    accuracy                           0.36      1395\n",
      "   macro avg       0.39      0.37      0.33      1395\n",
      "weighted avg       0.40      0.36      0.32      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.39      0.35        41\n",
      "           2       0.22      0.32      0.26        65\n",
      "           3       0.36      0.06      0.11        78\n",
      "           4       0.31      0.17      0.22        78\n",
      "           5       0.33      0.55      0.41        87\n",
      "\n",
      "    accuracy                           0.30       349\n",
      "   macro avg       0.31      0.30      0.27       349\n",
      "weighted avg       0.31      0.30      0.27       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predictions\n",
    "tr_pred=mod_dt.predict(X_train)\n",
    "te_pred=mod_dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train,tr_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,te_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.66      0.52       412\n",
      "           2       0.53      0.20      0.29       314\n",
      "           3       0.64      0.62      0.63       669\n",
      "\n",
      "    accuracy                           0.54      1395\n",
      "   macro avg       0.53      0.49      0.48      1395\n",
      "weighted avg       0.55      0.54      0.52      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.66      0.53       106\n",
      "           2       0.47      0.18      0.26        78\n",
      "           3       0.64      0.62      0.63       165\n",
      "\n",
      "    accuracy                           0.54       349\n",
      "   macro avg       0.52      0.49      0.47       349\n",
      "weighted avg       0.54      0.54      0.52       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### On 3 levels\n",
    "### on 3 classes\n",
    "mod_dt=DecisionTreeClassifier(class_weight='balanced',max_depth=5)\n",
    "mod_dt.fit(X_train,y1_train)\n",
    "\n",
    "tr_pred=mod_dt.predict(X_train)\n",
    "te_pred=mod_dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y1_train,tr_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y1_test,te_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
       "       'NumCountPerSentence', 'GF', 'FK', 'SMOG', 'AR', 'CL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.508007\n",
      "         Iterations: 27\n",
      "         Function evaluations: 32\n",
      "         Gradient evaluations: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Level </td>       <th>  Log-Likelihood:    </th> <td> -2103.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>    <th>  AIC:               </th> <td>   4233.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   4301.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Tue, 13 Jun 2023</td>  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>22:33:29</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  1395</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  1382</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    13</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mword_count</th>            <td>    0.2541</td> <td>    0.033</td> <td>    7.743</td> <td> 0.000</td> <td>    0.190</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mathprop</th>               <td>   -0.1341</td> <td>    0.048</td> <td>   -2.794</td> <td> 0.005</td> <td>   -0.228</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MathSymbolsPerSentence</th> <td>    0.1878</td> <td>    0.049</td> <td>    3.819</td> <td> 0.000</td> <td>    0.091</td> <td>    0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NumCountPerSentence</th>    <td>   -0.0777</td> <td>    0.024</td> <td>   -3.269</td> <td> 0.001</td> <td>   -0.124</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GF</th>                     <td>   -0.0284</td> <td>    0.016</td> <td>   -1.805</td> <td> 0.071</td> <td>   -0.059</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FK</th>                     <td>    0.0049</td> <td>    0.003</td> <td>    1.546</td> <td> 0.122</td> <td>   -0.001</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SMOG</th>                   <td>    0.0467</td> <td>    0.011</td> <td>    4.100</td> <td> 0.000</td> <td>    0.024</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR</th>                     <td>    0.0517</td> <td>    0.026</td> <td>    1.951</td> <td> 0.051</td> <td>   -0.000</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CL</th>                     <td>   -0.0117</td> <td>    0.018</td> <td>   -0.632</td> <td> 0.527</td> <td>   -0.048</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1/2</th>                    <td>   -0.7082</td> <td>    0.458</td> <td>   -1.545</td> <td> 0.122</td> <td>   -1.606</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2/3</th>                    <td>    0.3478</td> <td>    0.057</td> <td>    6.054</td> <td> 0.000</td> <td>    0.235</td> <td>    0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3/4</th>                    <td>    0.0290</td> <td>    0.052</td> <td>    0.562</td> <td> 0.574</td> <td>   -0.072</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4/5</th>                    <td>    0.1064</td> <td>    0.051</td> <td>    2.071</td> <td> 0.038</td> <td>    0.006</td> <td>    0.207</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OrderedModel Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:                 Level    Log-Likelihood:                -2103.7\n",
       "Model:                   OrderedModel   AIC:                             4233.\n",
       "Method:            Maximum Likelihood   BIC:                             4301.\n",
       "Date:                Tue, 13 Jun 2023                                         \n",
       "Time:                        22:33:29                                         \n",
       "No. Observations:                1395                                         \n",
       "Df Residuals:                    1382                                         \n",
       "Df Model:                          13                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Mword_count                0.2541      0.033      7.743      0.000       0.190       0.318\n",
       "mathprop                  -0.1341      0.048     -2.794      0.005      -0.228      -0.040\n",
       "MathSymbolsPerSentence     0.1878      0.049      3.819      0.000       0.091       0.284\n",
       "NumCountPerSentence       -0.0777      0.024     -3.269      0.001      -0.124      -0.031\n",
       "GF                        -0.0284      0.016     -1.805      0.071      -0.059       0.002\n",
       "FK                         0.0049      0.003      1.546      0.122      -0.001       0.011\n",
       "SMOG                       0.0467      0.011      4.100      0.000       0.024       0.069\n",
       "AR                         0.0517      0.026      1.951      0.051      -0.000       0.104\n",
       "CL                        -0.0117      0.018     -0.632      0.527      -0.048       0.025\n",
       "1/2                       -0.7082      0.458     -1.545      0.122      -1.606       0.190\n",
       "2/3                        0.3478      0.057      6.054      0.000       0.235       0.460\n",
       "3/4                        0.0290      0.052      0.562      0.574      -0.072       0.130\n",
       "4/5                        0.1064      0.051      2.071      0.038       0.006       0.207\n",
       "==========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Ordered Regression 5 classes\n",
    "ord_data=pd.concat([X_train,y_train],axis=1)\n",
    "mod_ordered=OrderedModel(ord_data['Level '],ord_data[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence','GF', 'FK', 'SMOG', 'AR', 'CL']],distr='logit',)\n",
    "\n",
    "res_log = mod_ordered.fit(method='bfgs')\n",
    "res_log.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_test=pd.concat([X_test,y_test],axis=1)\n",
    "pred_train=res_log.model.predict(res_log.params, exog=ord_data[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence','GF', 'FK', 'SMOG', 'AR', 'CL']])\n",
    "pred_test=res_log.model.predict(res_log.params, exog=ord_test[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence','GF', 'FK', 'SMOG', 'AR', 'CL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       137\n",
      "           2       0.30      0.35      0.32       275\n",
      "           3       0.25      0.35      0.29       314\n",
      "           4       0.23      0.13      0.17       320\n",
      "           5       0.40      0.52      0.45       349\n",
      "\n",
      "    accuracy                           0.31      1395\n",
      "   macro avg       0.24      0.27      0.25      1395\n",
      "weighted avg       0.27      0.31      0.28      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        41\n",
      "           2       0.29      0.34      0.31        65\n",
      "           3       0.28      0.40      0.33        78\n",
      "           4       0.30      0.17      0.21        78\n",
      "           5       0.38      0.52      0.44        87\n",
      "\n",
      "    accuracy                           0.32       349\n",
      "   macro avg       0.25      0.28      0.26       349\n",
      "weighted avg       0.28      0.32      0.29       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train1=np.argmax(pred_train, axis=1)+1\n",
    "pred_test1=np.argmax(pred_test, axis=1)+1\n",
    "print(classification_report(ord_data['Level '],pred_train1))\n",
    "print(\"\\n\")\n",
    "print(classification_report(ord_test['Level '],pred_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ordered 3 levels\n",
    "### for 3 levels\n",
    "ord_data1=pd.concat([X_train,y1_train],axis=1)\n",
    "ord_test1=pd.concat([X_test,y1_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.997104\n",
      "         Iterations: 29\n",
      "         Function evaluations: 32\n",
      "         Gradient evaluations: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Level </td>       <th>  Log-Likelihood:    </th> <td> -1391.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>    <th>  AIC:               </th> <td>   2804.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   2862.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Tue, 13 Jun 2023</td>  <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>22:33:30</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  1395</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  1384</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    11</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mword_count</th>            <td>    0.2802</td> <td>    0.040</td> <td>    7.088</td> <td> 0.000</td> <td>    0.203</td> <td>    0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mathprop</th>               <td>   -0.1327</td> <td>    0.056</td> <td>   -2.385</td> <td> 0.017</td> <td>   -0.242</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MathSymbolsPerSentence</th> <td>    0.2066</td> <td>    0.053</td> <td>    3.891</td> <td> 0.000</td> <td>    0.103</td> <td>    0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NumCountPerSentence</th>    <td>   -0.0847</td> <td>    0.026</td> <td>   -3.238</td> <td> 0.001</td> <td>   -0.136</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GF</th>                     <td>   -0.0262</td> <td>    0.017</td> <td>   -1.584</td> <td> 0.113</td> <td>   -0.059</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FK</th>                     <td>    0.0055</td> <td>    0.003</td> <td>    1.606</td> <td> 0.108</td> <td>   -0.001</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SMOG</th>                   <td>    0.0461</td> <td>    0.012</td> <td>    3.793</td> <td> 0.000</td> <td>    0.022</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR</th>                     <td>    0.0438</td> <td>    0.028</td> <td>    1.550</td> <td> 0.121</td> <td>   -0.012</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CL</th>                     <td>   -0.0053</td> <td>    0.020</td> <td>   -0.264</td> <td> 0.791</td> <td>   -0.044</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1/2</th>                    <td>    0.8503</td> <td>    0.489</td> <td>    1.741</td> <td> 0.082</td> <td>   -0.107</td> <td>    1.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2/3</th>                    <td>    0.0356</td> <td>    0.052</td> <td>    0.690</td> <td> 0.490</td> <td>   -0.066</td> <td>    0.137</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OrderedModel Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:                 Level    Log-Likelihood:                -1391.0\n",
       "Model:                   OrderedModel   AIC:                             2804.\n",
       "Method:            Maximum Likelihood   BIC:                             2862.\n",
       "Date:                Tue, 13 Jun 2023                                         \n",
       "Time:                        22:33:30                                         \n",
       "No. Observations:                1395                                         \n",
       "Df Residuals:                    1384                                         \n",
       "Df Model:                          11                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Mword_count                0.2802      0.040      7.088      0.000       0.203       0.358\n",
       "mathprop                  -0.1327      0.056     -2.385      0.017      -0.242      -0.024\n",
       "MathSymbolsPerSentence     0.2066      0.053      3.891      0.000       0.103       0.311\n",
       "NumCountPerSentence       -0.0847      0.026     -3.238      0.001      -0.136      -0.033\n",
       "GF                        -0.0262      0.017     -1.584      0.113      -0.059       0.006\n",
       "FK                         0.0055      0.003      1.606      0.108      -0.001       0.012\n",
       "SMOG                       0.0461      0.012      3.793      0.000       0.022       0.070\n",
       "AR                         0.0438      0.028      1.550      0.121      -0.012       0.099\n",
       "CL                        -0.0053      0.020     -0.264      0.791      -0.044       0.034\n",
       "1/2                        0.8503      0.489      1.741      0.082      -0.107       1.808\n",
       "2/3                        0.0356      0.052      0.690      0.490      -0.066       0.137\n",
       "==========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "mod_ordered=OrderedModel(ord_data1['Level '],ord_data1[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence','GF', 'FK', 'SMOG', 'AR', 'CL']],distr='logit')\n",
    "\n",
    "res_log = mod_ordered.fit(method='bfgs')\n",
    "res_log.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=res_log.model.predict(res_log.params, exog=ord_data1[['Mword_count', 'mathprop', 'MathSymbolsPerSentence','NumCountPerSentence','GF', 'FK', 'SMOG', 'AR', 'CL']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=res_log.model.predict(res_log.params, exog=ord_test1[['Mword_count', 'mathprop', 'MathSymbolsPerSentence',\n",
    "       'NumCountPerSentence','GF', 'FK', 'SMOG', 'AR', 'CL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.42      0.44       412\n",
      "           2       0.00      0.00      0.00       314\n",
      "           3       0.54      0.84      0.66       669\n",
      "\n",
      "    accuracy                           0.53      1395\n",
      "   macro avg       0.34      0.42      0.37      1395\n",
      "weighted avg       0.40      0.53      0.45      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.42      0.45       106\n",
      "           2       0.00      0.00      0.00        78\n",
      "           3       0.54      0.86      0.67       165\n",
      "\n",
      "    accuracy                           0.53       349\n",
      "   macro avg       0.35      0.43      0.37       349\n",
      "weighted avg       0.41      0.53      0.45       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train1=np.argmax(pred_train, axis=1)+1\n",
    "pred_test1=np.argmax(pred_test, axis=1)+1\n",
    "print(classification_report(ord_data1['Level '],pred_train1))\n",
    "print(\"\\n\")\n",
    "print(classification_report(ord_test1['Level '],pred_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 4.5940 - accuracy: 0.2473\n",
      "Epoch 2/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.9449 - accuracy: 0.2710\n",
      "Epoch 3/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.7734 - accuracy: 0.2695\n",
      "Epoch 4/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6915 - accuracy: 0.2882\n",
      "Epoch 5/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6838 - accuracy: 0.2803\n",
      "Epoch 6/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6450 - accuracy: 0.2796\n",
      "Epoch 7/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6343 - accuracy: 0.2760\n",
      "Epoch 8/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6250 - accuracy: 0.2796\n",
      "Epoch 9/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6115 - accuracy: 0.2824\n",
      "Epoch 10/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5759 - accuracy: 0.3133\n",
      "Epoch 11/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5747 - accuracy: 0.2918\n",
      "Epoch 12/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6044 - accuracy: 0.2760\n",
      "Epoch 13/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5833 - accuracy: 0.2860\n",
      "Epoch 14/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5680 - accuracy: 0.2996\n",
      "Epoch 15/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5624 - accuracy: 0.2996\n",
      "Epoch 16/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5635 - accuracy: 0.2882\n",
      "Epoch 17/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5930 - accuracy: 0.2753\n",
      "Epoch 18/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5368 - accuracy: 0.3204\n",
      "Epoch 19/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5610 - accuracy: 0.2781\n",
      "Epoch 20/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5714 - accuracy: 0.2975\n",
      "Epoch 21/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5511 - accuracy: 0.2989\n",
      "Epoch 22/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5267 - accuracy: 0.2946\n",
      "Epoch 23/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5431 - accuracy: 0.3061\n",
      "Epoch 24/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5384 - accuracy: 0.2925\n",
      "Epoch 25/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5437 - accuracy: 0.2889\n",
      "Epoch 26/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5492 - accuracy: 0.2982\n",
      "Epoch 27/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5535 - accuracy: 0.2946\n",
      "Epoch 28/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5441 - accuracy: 0.2789\n",
      "Epoch 29/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5445 - accuracy: 0.3047\n",
      "Epoch 30/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5555 - accuracy: 0.3125\n",
      "Epoch 31/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5281 - accuracy: 0.3032\n",
      "Epoch 32/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5102 - accuracy: 0.3032\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.05      0.09        41\n",
      "           2       0.30      0.15      0.20        65\n",
      "           3       0.34      0.36      0.35        78\n",
      "           4       0.60      0.04      0.07        78\n",
      "           5       0.30      0.77      0.43        87\n",
      "\n",
      "    accuracy                           0.32       349\n",
      "   macro avg       0.44      0.27      0.23       349\n",
      "weighted avg       0.42      0.32      0.25       349\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.04      0.08       137\n",
      "           2       0.32      0.18      0.23       275\n",
      "           3       0.29      0.32      0.31       314\n",
      "           4       0.44      0.01      0.02       320\n",
      "           5       0.33      0.83      0.47       349\n",
      "\n",
      "    accuracy                           0.32      1395\n",
      "   macro avg       0.38      0.28      0.22      1395\n",
      "weighted avg       0.36      0.32      0.25      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### ANN\n",
    "### ANN on 5 levels\n",
    "y5_train=to_categorical(y_train)\n",
    "y5_test=to_categorical(y_test)\n",
    "\n",
    "y5_train=y5_train[:,1:]\n",
    "y5_test=y5_test[:,1:]\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_dim=9, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y5_train, epochs=32, batch_size=16)\n",
    "pred_train=np.argmax(model.predict(X_train),axis=1)+1\n",
    "pred_test=np.argmax(model.predict(X_test),axis=1)+1\n",
    "\n",
    "print(classification_report(y_test,pred_test))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train,pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 6.1539 - accuracy: 0.3204\n",
      "Epoch 2/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.4101 - accuracy: 0.4208\n",
      "Epoch 3/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.2525 - accuracy: 0.4473\n",
      "Epoch 4/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.1926 - accuracy: 0.4509\n",
      "Epoch 5/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.1562 - accuracy: 0.4695\n",
      "Epoch 6/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.1153 - accuracy: 0.4832\n",
      "Epoch 7/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0950 - accuracy: 0.4918\n",
      "Epoch 8/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0842 - accuracy: 0.4910\n",
      "Epoch 9/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0609 - accuracy: 0.5054\n",
      "Epoch 10/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0445 - accuracy: 0.5133\n",
      "Epoch 11/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0511 - accuracy: 0.5075\n",
      "Epoch 12/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0446 - accuracy: 0.5061\n",
      "Epoch 13/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0272 - accuracy: 0.5097\n",
      "Epoch 14/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0419 - accuracy: 0.5104\n",
      "Epoch 15/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0281 - accuracy: 0.5276\n",
      "Epoch 16/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0204 - accuracy: 0.5075\n",
      "Epoch 17/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0214 - accuracy: 0.5133\n",
      "Epoch 18/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0271 - accuracy: 0.5190\n",
      "Epoch 19/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0289 - accuracy: 0.5075\n",
      "Epoch 20/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0283 - accuracy: 0.5068\n",
      "Epoch 21/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0110 - accuracy: 0.5068\n",
      "Epoch 22/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0466 - accuracy: 0.4953\n",
      "Epoch 23/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0109 - accuracy: 0.5211\n",
      "Epoch 24/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0132 - accuracy: 0.5219\n",
      "Epoch 25/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0211 - accuracy: 0.5075\n",
      "Epoch 26/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0188 - accuracy: 0.5219\n",
      "Epoch 27/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0109 - accuracy: 0.5011\n",
      "Epoch 28/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0164 - accuracy: 0.5075\n",
      "Epoch 29/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0227 - accuracy: 0.5011\n",
      "Epoch 30/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.9958 - accuracy: 0.5254\n",
      "Epoch 31/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0134 - accuracy: 0.5082\n",
      "Epoch 32/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0126 - accuracy: 0.5190\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.38      0.43       106\n",
      "           2       0.20      0.03      0.05        78\n",
      "           3       0.56      0.88      0.68       165\n",
      "\n",
      "    accuracy                           0.54       349\n",
      "   macro avg       0.42      0.43      0.39       349\n",
      "weighted avg       0.46      0.54      0.46       349\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.41      0.47       412\n",
      "           2       0.28      0.05      0.08       314\n",
      "           3       0.56      0.87      0.68       669\n",
      "\n",
      "    accuracy                           0.55      1395\n",
      "   macro avg       0.46      0.44      0.41      1395\n",
      "weighted avg       0.50      0.55      0.48      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### ANN\n",
    "####### on 3 levels\n",
    "y11_train=to_categorical(y1_train)\n",
    "y11_test=to_categorical(y1_test)\n",
    "\n",
    "y11_train=y11_train[:,1:]\n",
    "y11_test=y11_test[:,1:]\n",
    "\n",
    "model=Sequential()\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_dim=9, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y11_train, epochs=32, batch_size=16)\n",
    "\n",
    "\n",
    "pred_train=np.argmax(model.predict(X_train),axis=1)+1\n",
    "pred_test=np.argmax(model.predict(X_test),axis=1)+1\n",
    "\n",
    "print(classification_report(y1_test,pred_test))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y1_train,pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define the range of k values to evaluate\n",
    "k_values = range(2, 10)\n",
    "\n",
    "distortions = []\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=50)\n",
    "    kmeans.fit(X_train)\n",
    "    results.append(kmeans.labels_)\n",
    "    distortion = kmeans.inertia_\n",
    "    distortions.append(distortion)\n",
    "\n",
    "plt.plot(k_values, distortions, 'bx-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('Elbow Curve based on RI and Math Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ARI: 0.9705432572135104\n"
     ]
    }
   ],
   "source": [
    "### Adjusted RandIndex\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "\n",
    "# Set the number of clusters for k-means\n",
    "n_clusters = 3\n",
    "\n",
    "cluster_labels = []\n",
    "all_labels = []\n",
    "num_runs = 10\n",
    "for _ in range(num_runs):\n",
    "    perturbed_data = X_train + np.random.normal(scale=0.01, size=X_train.shape)  # Perturb the data\n",
    "    labels = kmeans.fit_predict(perturbed_data)\n",
    "    cluster_labels.append(labels)\n",
    "\n",
    "# Calculate similarity scores (ARI) between clusters\n",
    "ari_scores = []\n",
    "for i in range(len(cluster_labels)):\n",
    "    for j in range(i+1, len(cluster_labels)):\n",
    "        ari = adjusted_rand_score(cluster_labels[i], cluster_labels[j])\n",
    "        ari_scores.append(ari)\n",
    "\n",
    "# Assess cluster stability using the similarity scores\n",
    "average_ari = np.mean(ari_scores)\n",
    "print(\"Average ARI:\", average_ari)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: RI English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Only on RI ANN\n",
    "RI_data=pd.concat([RI,RI_Math_data['Level ']],axis=1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(RI_data.iloc[:,:-1],RI_data.iloc[:,-1],test_size=0.2,random_state=42)\n",
    "y1_train=y_train.replace({2:1,3:2,4:3,5:3})\n",
    "y1_test=y_test.replace({2:1,3:2,4:3,5:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GF', 'FK', 'SMOG', 'AR', 'CL', 'Level '], dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RI_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 15.6171 - accuracy: 0.2072\n",
      "Epoch 2/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 3.7715 - accuracy: 0.2093\n",
      "Epoch 3/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 2.1957 - accuracy: 0.2409\n",
      "Epoch 4/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.8312 - accuracy: 0.2703\n",
      "Epoch 5/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.7377 - accuracy: 0.2746\n",
      "Epoch 6/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.7153 - accuracy: 0.2523\n",
      "Epoch 7/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6728 - accuracy: 0.2609\n",
      "Epoch 8/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6362 - accuracy: 0.2688\n",
      "Epoch 9/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6169 - accuracy: 0.2638\n",
      "Epoch 10/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6357 - accuracy: 0.2559\n",
      "Epoch 11/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5906 - accuracy: 0.2667\n",
      "Epoch 12/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6268 - accuracy: 0.2581\n",
      "Epoch 13/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6031 - accuracy: 0.2667\n",
      "Epoch 14/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5974 - accuracy: 0.2738\n",
      "Epoch 15/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6017 - accuracy: 0.2659\n",
      "Epoch 16/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5762 - accuracy: 0.2796\n",
      "Epoch 17/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5685 - accuracy: 0.2817\n",
      "Epoch 18/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5969 - accuracy: 0.2659\n",
      "Epoch 19/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5707 - accuracy: 0.2667\n",
      "Epoch 20/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5950 - accuracy: 0.2703\n",
      "Epoch 21/32\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1.5683 - accuracy: 0.2760\n",
      "Epoch 22/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5712 - accuracy: 0.2875\n",
      "Epoch 23/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5707 - accuracy: 0.2667\n",
      "Epoch 24/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5670 - accuracy: 0.2796\n",
      "Epoch 25/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5595 - accuracy: 0.2710\n",
      "Epoch 26/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5605 - accuracy: 0.2695\n",
      "Epoch 27/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5628 - accuracy: 0.2860\n",
      "Epoch 28/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5627 - accuracy: 0.2803\n",
      "Epoch 29/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5711 - accuracy: 0.2681\n",
      "Epoch 30/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5580 - accuracy: 0.2968\n",
      "Epoch 31/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5647 - accuracy: 0.2846\n",
      "Epoch 32/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5757 - accuracy: 0.2688\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.07      0.12        41\n",
      "           2       0.17      0.48      0.25        65\n",
      "           3       0.33      0.01      0.02        78\n",
      "           4       0.00      0.00      0.00        78\n",
      "           5       0.31      0.56      0.40        87\n",
      "\n",
      "    accuracy                           0.24       349\n",
      "   macro avg       0.24      0.23      0.16       349\n",
      "weighted avg       0.23      0.24      0.17       349\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.02      0.04       137\n",
      "           2       0.24      0.64      0.35       275\n",
      "           3       0.33      0.03      0.05       314\n",
      "           4       0.38      0.02      0.04       320\n",
      "           5       0.34      0.61      0.44       349\n",
      "\n",
      "    accuracy                           0.29      1395\n",
      "   macro avg       0.31      0.26      0.18      1395\n",
      "weighted avg       0.32      0.29      0.20      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### ANN on 5 levels\n",
    "y5_train=to_categorical(y_train)\n",
    "y5_test=to_categorical(y_test)\n",
    "\n",
    "y5_train=y5_train[:,1:]\n",
    "y5_test=y5_test[:,1:]\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_dim=5, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y5_train, epochs=32, batch_size=16)\n",
    "pred_train=np.argmax(model.predict(X_train),axis=1)+1\n",
    "pred_test=np.argmax(model.predict(X_test),axis=1)+1\n",
    "\n",
    "print(classification_report(y_test,pred_test))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train,pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 3.4808 - accuracy: 0.4079\n",
      "Epoch 2/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5819 - accuracy: 0.4401\n",
      "Epoch 3/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.3494 - accuracy: 0.4351\n",
      "Epoch 4/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.2293 - accuracy: 0.4717\n",
      "Epoch 5/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.1515 - accuracy: 0.4659\n",
      "Epoch 6/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.1609 - accuracy: 0.4581\n",
      "Epoch 7/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.1029 - accuracy: 0.4767\n",
      "Epoch 8/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0831 - accuracy: 0.4889\n",
      "Epoch 9/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0580 - accuracy: 0.4918\n",
      "Epoch 10/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0792 - accuracy: 0.4789\n",
      "Epoch 11/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0617 - accuracy: 0.4796\n",
      "Epoch 12/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0947 - accuracy: 0.4681\n",
      "Epoch 13/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0890 - accuracy: 0.4695\n",
      "Epoch 14/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0735 - accuracy: 0.4810\n",
      "Epoch 15/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0543 - accuracy: 0.4889\n",
      "Epoch 16/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0856 - accuracy: 0.4789\n",
      "Epoch 17/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0702 - accuracy: 0.4738\n",
      "Epoch 18/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0941 - accuracy: 0.4746\n",
      "Epoch 19/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0600 - accuracy: 0.4903\n",
      "Epoch 20/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0707 - accuracy: 0.4609\n",
      "Epoch 21/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0624 - accuracy: 0.4832\n",
      "Epoch 22/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0533 - accuracy: 0.5018\n",
      "Epoch 23/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0362 - accuracy: 0.5032\n",
      "Epoch 24/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0589 - accuracy: 0.4717\n",
      "Epoch 25/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0533 - accuracy: 0.4896\n",
      "Epoch 26/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0919 - accuracy: 0.4731\n",
      "Epoch 27/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0414 - accuracy: 0.4968\n",
      "Epoch 28/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0488 - accuracy: 0.4774\n",
      "Epoch 29/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0580 - accuracy: 0.4767\n",
      "Epoch 30/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0679 - accuracy: 0.4688\n",
      "Epoch 31/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0486 - accuracy: 0.4724\n",
      "Epoch 32/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0642 - accuracy: 0.4767\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.34      0.40       106\n",
      "           2       1.00      0.01      0.03        78\n",
      "           3       0.53      0.88      0.66       165\n",
      "\n",
      "    accuracy                           0.52       349\n",
      "   macro avg       0.68      0.41      0.36       349\n",
      "weighted avg       0.63      0.52      0.44       349\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.34      0.40       412\n",
      "           2       1.00      0.00      0.01       314\n",
      "           3       0.53      0.87      0.66       669\n",
      "\n",
      "    accuracy                           0.52      1395\n",
      "   macro avg       0.67      0.40      0.35      1395\n",
      "weighted avg       0.62      0.52      0.43      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### ANN 3 classes\n",
    "\n",
    "y11_train=to_categorical(y1_train)\n",
    "y11_test=to_categorical(y1_test)\n",
    "\n",
    "y11_train=y11_train[:,1:]\n",
    "y11_test=y11_test[:,1:]\n",
    "\n",
    "model=Sequential()\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_dim=5, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y11_train, epochs=32, batch_size=16)\n",
    "\n",
    "\n",
    "pred_train=np.argmax(model.predict(X_train),axis=1)+1\n",
    "pred_test=np.argmax(model.predict(X_test),axis=1)+1\n",
    "\n",
    "print(classification_report(y1_test,pred_test))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y1_train,pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.47      0.43       137\n",
      "           2       0.37      0.19      0.25       275\n",
      "           3       0.30      0.19      0.23       314\n",
      "           4       0.40      0.21      0.28       320\n",
      "           5       0.37      0.76      0.50       349\n",
      "\n",
      "    accuracy                           0.36      1395\n",
      "   macro avg       0.37      0.36      0.34      1395\n",
      "weighted avg       0.36      0.36      0.33      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.24      0.24        41\n",
      "           2       0.36      0.25      0.29        65\n",
      "           3       0.38      0.23      0.29        78\n",
      "           4       0.18      0.09      0.12        78\n",
      "           5       0.33      0.68      0.45        87\n",
      "\n",
      "    accuracy                           0.32       349\n",
      "   macro avg       0.30      0.30      0.28       349\n",
      "weighted avg       0.30      0.32      0.29       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Decision Trees\n",
    "\n",
    "### Test on 5 levels\n",
    "mod_dt=DecisionTreeClassifier(class_weight='balanced',max_depth=5)\n",
    "mod_dt.fit(X_train,y_train)\n",
    "\n",
    "## Predictions\n",
    "tr_pred=mod_dt.predict(X_train)\n",
    "te_pred=mod_dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train,tr_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,te_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.70      0.50       412\n",
      "           2       0.46      0.23      0.31       314\n",
      "           3       0.66      0.48      0.56       669\n",
      "\n",
      "    accuracy                           0.49      1395\n",
      "   macro avg       0.50      0.47      0.45      1395\n",
      "weighted avg       0.53      0.49      0.48      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.63      0.45       106\n",
      "           2       0.27      0.13      0.17        78\n",
      "           3       0.57      0.42      0.49       165\n",
      "\n",
      "    accuracy                           0.42       349\n",
      "   macro avg       0.40      0.39      0.37       349\n",
      "weighted avg       0.44      0.42      0.41       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Decision Tree on 3 levels\n",
    "mod_dt=DecisionTreeClassifier(class_weight='balanced',max_depth=5)\n",
    "mod_dt.fit(X_train,y1_train)\n",
    "\n",
    "tr_pred=mod_dt.predict(X_train)\n",
    "te_pred=mod_dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y1_train,tr_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y1_test,te_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the range of k values to evaluate\n",
    "k_values = range(2, 10)\n",
    "\n",
    "distortions = []\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=50)\n",
    "    kmeans.fit(X_train)\n",
    "    results.append(kmeans.labels_)\n",
    "    distortion = kmeans.inertia_\n",
    "    distortions.append(distortion)\n",
    "\n",
    "plt.plot(k_values, distortions, 'bx-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('Elbow Curve based on RI')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ARI: 0.9967908978399902\n"
     ]
    }
   ],
   "source": [
    "### Adjusted RandIndex\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "\n",
    "# Set the number of clusters for k-means\n",
    "n_clusters = 3\n",
    "\n",
    "cluster_labels = []\n",
    "all_labels = []\n",
    "num_runs = 10\n",
    "for _ in range(num_runs):\n",
    "    perturbed_data = X_train + np.random.normal(scale=0.01, size=X_train.shape)  # Perturb the data\n",
    "    labels = kmeans.fit_predict(perturbed_data)\n",
    "    cluster_labels.append(labels)\n",
    "\n",
    "# Calculate similarity scores (ARI) between clusters\n",
    "ari_scores = []\n",
    "for i in range(len(cluster_labels)):\n",
    "    for j in range(i+1, len(cluster_labels)):\n",
    "        ari = adjusted_rand_score(cluster_labels[i], cluster_labels[j])\n",
    "        ari_scores.append(ari)\n",
    "\n",
    "# Assess cluster stability using the similarity scores\n",
    "average_ari = np.mean(ari_scores)\n",
    "print(\"Average ARI:\", average_ari)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.538171\n",
      "         Iterations: 25\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n"
     ]
    }
   ],
   "source": [
    "### Ordered regression  5 classes\n",
    "#### Ordered Regression 5 classes\n",
    "ord_data=pd.concat([X_train,y_train],axis=1)\n",
    "mod_ordered=OrderedModel(ord_data['Level '],ord_data[['GF', 'FK', 'SMOG', 'AR', 'CL']],distr='logit')\n",
    "\n",
    "res_log = mod_ordered.fit(method='bfgs')\n",
    "res_log.summary()\n",
    "\n",
    "\n",
    "ord_test=pd.concat([X_test,y_test],axis=1)\n",
    "pred_train=res_log.model.predict(res_log.params, exog=ord_data[['GF', 'FK', 'SMOG', 'AR', 'CL']])\n",
    "pred_test=res_log.model.predict(res_log.params, exog=ord_test[['GF', 'FK', 'SMOG', 'AR', 'CL']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       137\n",
      "           2       0.29      0.32      0.30       275\n",
      "           3       0.27      0.26      0.27       314\n",
      "           4       0.18      0.02      0.04       320\n",
      "           5       0.31      0.67      0.43       349\n",
      "\n",
      "    accuracy                           0.29      1395\n",
      "   macro avg       0.21      0.25      0.21      1395\n",
      "weighted avg       0.24      0.29      0.24      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        41\n",
      "           2       0.20      0.23      0.21        65\n",
      "           3       0.24      0.23      0.24        78\n",
      "           4       0.22      0.03      0.05        78\n",
      "           5       0.28      0.61      0.38        87\n",
      "\n",
      "    accuracy                           0.25       349\n",
      "   macro avg       0.19      0.22      0.18       349\n",
      "weighted avg       0.21      0.25      0.20       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train1=np.argmax(pred_train, axis=1)+1\n",
    "pred_test1=np.argmax(pred_test, axis=1)+1\n",
    "print(classification_report(ord_data['Level '],pred_train1))\n",
    "print(\"\\n\")\n",
    "print(classification_report(ord_test['Level '],pred_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GF', 'FK', 'SMOG', 'AR', 'CL'], dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.026114\n",
      "         Iterations: 21\n",
      "         Function evaluations: 24\n",
      "         Gradient evaluations: 24\n"
     ]
    }
   ],
   "source": [
    "#### Ordered Regression 3 levels\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "ord_data1=pd.concat([X_train,y1_train],axis=1)\n",
    "mod_ordered1=OrderedModel(ord_data1['Level '],ord_data1[['GF', 'FK', 'SMOG', 'AR', 'CL']],distr='logit')\n",
    "\n",
    "res_log1 = mod_ordered1.fit(method='bfgs')\n",
    "res_log1.summary()\n",
    "\n",
    "\n",
    "ord_test1=pd.concat([X_test,y1_test],axis=1)\n",
    "pred_train=res_log1.model.predict(res_log1.params, exog=ord_data1[['GF', 'FK', 'SMOG', 'AR', 'CL']])\n",
    "pred_test=res_log1.model.predict(res_log1.params, exog=ord_test1[['GF', 'FK', 'SMOG', 'AR', 'CL']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.29      0.36       412\n",
      "           2       0.00      0.00      0.00       314\n",
      "           3       0.51      0.87      0.65       669\n",
      "\n",
      "    accuracy                           0.50      1395\n",
      "   macro avg       0.32      0.39      0.33      1395\n",
      "weighted avg       0.38      0.50      0.41      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train=np.argmax(pred_train,axis=1)+1\n",
    "pred_test=np.argmax(pred_test,axis=1)+1\n",
    "\n",
    "print(classification_report(ord_data1['Level '],pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.32      0.39       106\n",
      "           2       0.00      0.00      0.00        78\n",
      "           3       0.52      0.88      0.65       165\n",
      "\n",
      "    accuracy                           0.52       349\n",
      "   macro avg       0.34      0.40      0.35       349\n",
      "weighted avg       0.40      0.52      0.43       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ord_test1['Level '],pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "####3 MAth Equation\n",
    "RI_Math_data['computed']=RI_Math_data['Mword_count']*0.2824 + RI_Math_data['mathprop']*(-0.0773) + RI_Math_data['MathSymbolsPerSentence']*(.1345)+ RI_Math_data['NumCountPerSentence']*(-0.0262)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['GF','FK','SMOG','AR','CL','computed','Level ']\n",
    "new_data=RI_Math_data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(new_data.iloc[:,:-1],new_data.iloc[:,-1],test_size=0.2,random_state=42)\n",
    "y1_train=y_train.replace({2:1,3:2,4:3,5:3})\n",
    "y1_test=y_test.replace({2:1,3:2,4:3,5:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.55      0.45       137\n",
      "           2       0.31      0.40      0.35       275\n",
      "           3       0.35      0.30      0.32       314\n",
      "           4       0.47      0.12      0.19       320\n",
      "           5       0.44      0.61      0.51       349\n",
      "\n",
      "    accuracy                           0.38      1395\n",
      "   macro avg       0.39      0.40      0.36      1395\n",
      "weighted avg       0.39      0.38      0.36      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.27      0.25        41\n",
      "           2       0.26      0.38      0.31        65\n",
      "           3       0.36      0.29      0.32        78\n",
      "           4       0.19      0.08      0.11        78\n",
      "           5       0.41      0.52      0.45        87\n",
      "\n",
      "    accuracy                           0.32       349\n",
      "   macro avg       0.29      0.31      0.29       349\n",
      "weighted avg       0.30      0.32      0.30       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Decision Tree on 5 levels\n",
    "mod_dt=DecisionTreeClassifier(class_weight='balanced',max_depth=5)\n",
    "mod_dt.fit(X_train,y_train)\n",
    "\n",
    "tr_pred=mod_dt.predict(X_train)\n",
    "te_pred=mod_dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train,tr_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,te_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.69      0.56       412\n",
      "           2       0.41      0.34      0.37       314\n",
      "           3       0.67      0.54      0.60       669\n",
      "\n",
      "    accuracy                           0.54      1395\n",
      "   macro avg       0.52      0.52      0.51      1395\n",
      "weighted avg       0.55      0.54      0.54      1395\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.61      0.52       106\n",
      "           2       0.33      0.27      0.30        78\n",
      "           3       0.69      0.58      0.63       165\n",
      "\n",
      "    accuracy                           0.52       349\n",
      "   macro avg       0.49      0.49      0.48       349\n",
      "weighted avg       0.54      0.52      0.52       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Decision Tree on 3 levels\n",
    "mod_dt=DecisionTreeClassifier(class_weight='balanced',max_depth=5)\n",
    "mod_dt.fit(X_train,y1_train)\n",
    "\n",
    "tr_pred=mod_dt.predict(X_train)\n",
    "te_pred=mod_dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y1_train,tr_pred))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y1_test,te_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 12.8831 - accuracy: 0.2022\n",
      "Epoch 2/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 2.3269 - accuracy: 0.2409\n",
      "Epoch 3/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.9448 - accuracy: 0.2530\n",
      "Epoch 4/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.8296 - accuracy: 0.2516\n",
      "Epoch 5/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.7685 - accuracy: 0.2559\n",
      "Epoch 6/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.7281 - accuracy: 0.2595\n",
      "Epoch 7/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6957 - accuracy: 0.2724\n",
      "Epoch 8/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6928 - accuracy: 0.2631\n",
      "Epoch 9/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6534 - accuracy: 0.2631\n",
      "Epoch 10/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6358 - accuracy: 0.2573\n",
      "Epoch 11/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6271 - accuracy: 0.2681\n",
      "Epoch 12/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6130 - accuracy: 0.2738\n",
      "Epoch 13/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.6021 - accuracy: 0.2839\n",
      "Epoch 14/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5969 - accuracy: 0.2703\n",
      "Epoch 15/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5674 - accuracy: 0.2846\n",
      "Epoch 16/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5703 - accuracy: 0.2796\n",
      "Epoch 17/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5858 - accuracy: 0.2839\n",
      "Epoch 18/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5580 - accuracy: 0.2832\n",
      "Epoch 19/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5862 - accuracy: 0.2896\n",
      "Epoch 20/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5618 - accuracy: 0.2824\n",
      "Epoch 21/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5649 - accuracy: 0.2982\n",
      "Epoch 22/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5659 - accuracy: 0.2781\n",
      "Epoch 23/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5515 - accuracy: 0.2860\n",
      "Epoch 24/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5381 - accuracy: 0.2932\n",
      "Epoch 25/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5396 - accuracy: 0.2882\n",
      "Epoch 26/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5543 - accuracy: 0.3032\n",
      "Epoch 27/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5374 - accuracy: 0.3082\n",
      "Epoch 28/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5606 - accuracy: 0.2910\n",
      "Epoch 29/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5256 - accuracy: 0.3047\n",
      "Epoch 30/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5227 - accuracy: 0.3004\n",
      "Epoch 31/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5459 - accuracy: 0.2975\n",
      "Epoch 32/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.5384 - accuracy: 0.3011\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.29      0.30        41\n",
      "           2       0.00      0.00      0.00        65\n",
      "           3       0.25      0.47      0.32        78\n",
      "           4       0.08      0.01      0.02        78\n",
      "           5       0.33      0.56      0.42        87\n",
      "\n",
      "    accuracy                           0.28       349\n",
      "   macro avg       0.19      0.27      0.21       349\n",
      "weighted avg       0.19      0.28      0.22       349\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.27      0.28       137\n",
      "           2       0.20      0.00      0.01       275\n",
      "           3       0.26      0.51      0.35       314\n",
      "           4       0.39      0.08      0.13       320\n",
      "           5       0.37      0.62      0.47       349\n",
      "\n",
      "    accuracy                           0.32      1395\n",
      "   macro avg       0.30      0.30      0.25      1395\n",
      "weighted avg       0.31      0.32      0.25      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### ANN on 5 levels\n",
    "y5_train=to_categorical(y_train)\n",
    "y5_test=to_categorical(y_test)\n",
    "\n",
    "y5_train=y5_train[:,1:]\n",
    "y5_test=y5_test[:,1:]\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_dim=6, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y5_train, epochs=32, batch_size=16)\n",
    "pred_train=np.argmax(model.predict(X_train),axis=1)+1\n",
    "pred_test=np.argmax(model.predict(X_test),axis=1)+1\n",
    "\n",
    "print(classification_report(y_test,pred_test))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_train,pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "88/88 [==============================] - 1s 1ms/step - loss: 6.5121 - accuracy: 0.3799\n",
      "Epoch 2/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.2647 - accuracy: 0.4667\n",
      "Epoch 3/32\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 1.1681 - accuracy: 0.4738\n",
      "Epoch 4/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.1613 - accuracy: 0.4810\n",
      "Epoch 5/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.1038 - accuracy: 0.4781\n",
      "Epoch 6/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0812 - accuracy: 0.4853\n",
      "Epoch 7/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0610 - accuracy: 0.4860\n",
      "Epoch 8/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0976 - accuracy: 0.4509\n",
      "Epoch 9/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0423 - accuracy: 0.5068\n",
      "Epoch 10/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0489 - accuracy: 0.5039\n",
      "Epoch 11/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0288 - accuracy: 0.4996\n",
      "Epoch 12/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0431 - accuracy: 0.4975\n",
      "Epoch 13/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0473 - accuracy: 0.4939\n",
      "Epoch 14/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0455 - accuracy: 0.4975\n",
      "Epoch 15/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0547 - accuracy: 0.4896\n",
      "Epoch 16/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0356 - accuracy: 0.4968\n",
      "Epoch 17/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0343 - accuracy: 0.5097\n",
      "Epoch 18/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0481 - accuracy: 0.4932\n",
      "Epoch 19/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0385 - accuracy: 0.5018\n",
      "Epoch 20/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0298 - accuracy: 0.5111\n",
      "Epoch 21/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0214 - accuracy: 0.5140\n",
      "Epoch 22/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0295 - accuracy: 0.5025\n",
      "Epoch 23/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0229 - accuracy: 0.5011\n",
      "Epoch 24/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0306 - accuracy: 0.5111\n",
      "Epoch 25/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0230 - accuracy: 0.4946\n",
      "Epoch 26/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0394 - accuracy: 0.5032\n",
      "Epoch 27/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0333 - accuracy: 0.4910\n",
      "Epoch 28/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0204 - accuracy: 0.4910\n",
      "Epoch 29/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0164 - accuracy: 0.5090\n",
      "Epoch 30/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0199 - accuracy: 0.5054\n",
      "Epoch 31/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0422 - accuracy: 0.4932\n",
      "Epoch 32/32\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 1.0471 - accuracy: 0.4932\n",
      "44/44 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.09      0.17       106\n",
      "           2       0.11      0.03      0.04        78\n",
      "           3       0.49      0.94      0.64       165\n",
      "\n",
      "    accuracy                           0.48       349\n",
      "   macro avg       0.45      0.35      0.28       349\n",
      "weighted avg       0.49      0.48      0.36       349\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.08      0.14       412\n",
      "           2       0.23      0.06      0.10       314\n",
      "           3       0.51      0.95      0.66       669\n",
      "\n",
      "    accuracy                           0.49      1395\n",
      "   macro avg       0.44      0.36      0.30      1395\n",
      "weighted avg       0.47      0.49      0.38      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### ANN 3 classes\n",
    "\n",
    "y11_train=to_categorical(y1_train)\n",
    "y11_test=to_categorical(y1_test)\n",
    "\n",
    "y11_train=y11_train[:,1:]\n",
    "y11_test=y11_test[:,1:]\n",
    "\n",
    "model=Sequential()\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_dim=6, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y11_train, epochs=32, batch_size=16)\n",
    "\n",
    "\n",
    "pred_train=np.argmax(model.predict(X_train),axis=1)+1\n",
    "pred_test=np.argmax(model.predict(X_test),axis=1)+1\n",
    "\n",
    "print(classification_report(y1_test,pred_test))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y1_train,pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27168458781362004"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "classifier=\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and calculate the accuracy scores\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=kfold)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29032258, 0.2437276 , 0.25806452, 0.31182796, 0.25089606])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_8\" is incompatible with the layer: expected shape=(None, 5), found shape=(None, 6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32284\\1273774600.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Once the model is trained, you can use it for predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Pawan\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_8\" is incompatible with the layer: expected shape=(None, 5), found shape=(None, 6)\n"
     ]
    }
   ],
   "source": [
    "y2_train= to_categorical(y_train)\n",
    "y2_train=y2_train[:,1:]\n",
    "y2_test=to_categorical(y_test)\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_dim=5, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y2_train, epochs=32, batch_size=16)\n",
    "\n",
    "# Once the model is trained, you can use it for predictions\n",
    "# Assuming X_test is your test data\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_test=y2_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Predictions\n",
    "pred_train=np.argmax(model.predict(X_train),axis=1)+1\n",
    "pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=np.argmax(model.predict(X_test),axis=1)+1\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train,pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### on 3 levels\n",
    "y11_train=to_categorical(y1_train)\n",
    "y11_test=to_categorical(y1_test)\n",
    "\n",
    "y11_train=y11_train[:,1:]\n",
    "y11_test=y11_test[:,1:]\n",
    "\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_dim=5, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train, y11_train, epochs=32, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=np.argmax(model.predict(X_train),axis=1)+1\n",
    "pred_test=np.argmax(model.predict(X_test),axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1_train,pred_train))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y1_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
